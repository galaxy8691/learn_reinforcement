{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data_log(a, b, c, max_value=10000):\n",
    "    \"\"\"\n",
    "    使用log1p进行归一化，并确保结果在0-1之间\n",
    "    \"\"\"\n",
    "    # 确保没有负值\n",
    "    a = max(0, a)\n",
    "    b = max(0, b)\n",
    "    c = max(0, c)\n",
    "    \n",
    "    # 使用log1p变换\n",
    "    a_log = np.log1p(a)\n",
    "    b_log = np.log1p(b)\n",
    "    c_log = np.log1p(c)\n",
    "    \n",
    "    # 计算归一化因子 - 使用理论最大值\n",
    "    max_log = np.log1p(2*max_value)\n",
    "    \n",
    "    # 归一化到0-1范围\n",
    "    a_norm = a_log / max_log\n",
    "    b_norm = b_log / max_log\n",
    "    c_norm = c_log / max_log\n",
    "    \n",
    "    return a_norm, b_norm, c_norm\n",
    "\n",
    "def denormalize_data(a_norm, b_norm, c_norm, max_value=10000):\n",
    "    \"\"\"\n",
    "    将归一化的数据转换回原始范围\n",
    "    \n",
    "    参数:\n",
    "    a_norm, b_norm, c_norm: 归一化的值\n",
    "    max_value: 加数的最大可能值\n",
    "    \n",
    "    返回:\n",
    "    原始范围的a, b, c\n",
    "    \"\"\"\n",
    "    a = a_norm * max_value\n",
    "    b = b_norm * max_value\n",
    "    c = c_norm * (2 * max_value)\n",
    "    \n",
    "    return a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdditionNet, self).__init__()\n",
    "        # 简单的三层网络\n",
    "        self.fc1 = nn.Linear(3, 32)  # 输入层\n",
    "        self.fc2 = nn.Linear(32, 16) # 隐藏层\n",
    "        self.fc3 = nn.Linear(16, 2)  # 输出层：[错误概率, 正确概率]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.softmax(self.fc3(x), dim=1)  # 使用softmax确保两个输出和为1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(num_samples=10000, max_value=10000):\n",
    "\tdata = []\n",
    "\tlabels = []\n",
    "    \n",
    "\tfor _ in range(num_samples):\n",
    "\t\ta = np.random.uniform(0, max_value)\n",
    "\t\tb = np.random.uniform(0, max_value)\n",
    "        \n",
    "\t\tif np.random.random() < 0.5:\n",
    "\t\t\tc = a + b  # 正确答案\n",
    "\t\t\tlabel = [0, 1]\n",
    "\t\telse:\n",
    "\t\t\t# 更多样化的错误率\n",
    "\t\t\terror_rate = np.random.choice([\n",
    "\t\t\t\tnp.random.uniform(0.01, 0.05),  # 小误差(1-5%)\n",
    "\t\t\t\tnp.random.uniform(0.05, 0.10),  # 中误差(5-10%) \n",
    "\t\t\t\tnp.random.uniform(0.10, 0.30),  # 大误差(10-30%)\n",
    "\t\t\t])\n",
    "\t\t\tc = a + b * (1 + error_rate * (1 if np.random.random() < 0.5 else -1))\n",
    "\t\t\tlabel = [1, 0]\n",
    "        \n",
    "        # 归一化\n",
    "\t\ta_norm, b_norm, c_norm = normalize_data_log(a, b, c, max_value)\n",
    "\t\t\n",
    "\t\tdata.append([a_norm, b_norm, c_norm])\n",
    "\t\tlabels.append(label)\n",
    "\n",
    "\treturn torch.tensor(data, dtype=torch.float32), torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "def check_addition(a, b, c, max_value=10000):\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\ta_norm, b_norm, c_norm = normalize_data_log(a, b, c, max_value)\n",
    "\t\tinput_data = torch.tensor([[a_norm, b_norm, c_norm]], dtype=torch.float32)\n",
    "\t\tprobabilities = model(input_data)\n",
    "\t\tprint(f\"原始输出: {probabilities}\")  # 打印原始输出\n",
    "\t\treturn probabilities[0, 1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mixed_data(num_samples=80000):\n",
    "    \"\"\"生成混合难度的数据集，包含不同范围的加法问题\"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    # 每个难度范围的样本数量\n",
    "    samples_per_range = num_samples \n",
    "    \n",
    "    # 生成四个不同难度的数据\n",
    "    for max_value in [10, 100, 1000, 10000]:\n",
    "        for _ in range(samples_per_range):\n",
    "            a = np.random.uniform(0, max_value)\n",
    "            b = np.random.uniform(0, max_value)\n",
    "            \n",
    "            if np.random.random() < 0.5:\n",
    "                c = a + b  # 正确答案\n",
    "                label = [0, 1]  # [错误, 正确]\n",
    "            else:\n",
    "                # 生成错误答案，错误幅度与数值范围相适应\n",
    "                error_rate = np.random.uniform(0.01, 0.1)\n",
    "                error = (a + b) * error_rate * (1 if np.random.random() < 0.5 else -1)\n",
    "                c = a + b + error\n",
    "                label = [1, 0]  # [错误, 正确]\n",
    "            \n",
    "            # 归一化\n",
    "            a_norm, b_norm, c_norm = normalize_data_log(a, b, c, 10000)  # 始终使用最大范围归一化\n",
    "            \n",
    "            data.append([a_norm, b_norm, c_norm])\n",
    "            labels.append(label)\n",
    "    \n",
    "    # 打乱数据\n",
    "    combined = list(zip(data, labels))\n",
    "    np.random.shuffle(combined)\n",
    "    data, labels = zip(*combined)\n",
    "    \n",
    "    return torch.tensor(data, dtype=torch.float32), torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "def curriculum_training(model, epochs_per_stage=100):\n",
    "    stages = [\n",
    "        {\"max_value\": 10, \"name\": \"10以内加法\"},\n",
    "        {\"max_value\": 100, \"name\": \"100以内加法\"},\n",
    "        {\"max_value\": 1000, \"name\": \"1000以内加法\"},\n",
    "        {\"max_value\": 10000, \"name\": \"10000以内加法\"}\n",
    "    ]\n",
    "    \n",
    "    # 为每个阶段保存一个检查点\n",
    "    for stage_idx, stage in enumerate(stages):\n",
    "        print(f\"\\n开始训练阶段 {stage_idx+1}: {stage['name']}\")\n",
    "        max_value = stage[\"max_value\"]\n",
    "        \n",
    "        # 为当前难度生成数据\n",
    "        X_train, y_train = generate_data(num_samples=8000, max_value=max_value)\n",
    "        X_val, y_val = generate_data(num_samples=1000, max_value=max_value)\n",
    "        \n",
    "        # 将数据移到设备\n",
    "        X_train = X_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "        X_val = X_val.to(device)\n",
    "        y_val = y_val.to(device)\n",
    "        \n",
    "        # 训练当前阶段\n",
    "        batch_size = 1024\n",
    "        for epoch in range(epochs_per_stage):\n",
    "            # 训练模式\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            indices = torch.randperm(len(X_train))\n",
    "            \n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                batch_indices = indices[i:i+batch_size]\n",
    "                inputs = X_train[batch_indices]\n",
    "                targets = y_train[batch_indices]\n",
    "                \n",
    "                # 前向传播\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                # 反向传播和优化\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            train_loss = total_loss / (len(X_train) / batch_size)\n",
    "            \n",
    "            # 验证\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_outputs = model(X_val)\n",
    "                val_loss = criterion(val_outputs, y_val).item()\n",
    "                \n",
    "                # 计算准确率\n",
    "                _, val_predicted = torch.max(val_outputs, 1)\n",
    "                _, val_true_labels = torch.max(y_val, 1)\n",
    "                val_accuracy = (val_predicted == val_true_labels).float().mean().item()\n",
    "            \n",
    "            print(f'阶段 {stage_idx+1} 轮次 {epoch+1}/{epochs_per_stage}, '\n",
    "                  f'训练损失: {train_loss:.4f}, 验证损失: {val_loss:.4f}, '\n",
    "                  f'验证准确率: {val_accuracy:.4f}')\n",
    "            \n",
    "            # 如果验证准确率达到高水平，提前进入下一阶段\n",
    "            if val_accuracy > 0.95:\n",
    "                print(f\"阶段 {stage_idx+1} 提前完成! 验证准确率: {val_accuracy:.4f}\")\n",
    "                break\n",
    "                \n",
    "        # 保存阶段检查点\n",
    "        torch.save(model.state_dict(), f\"model_stage_{stage_idx+1}.pt\")\n",
    "        \n",
    "    # 最终阶段：混合数据训练\n",
    "    print(\"\\n开始最终整合阶段: 混合数据训练\")\n",
    "    X_train, y_train = generate_mixed_data()  # 生成各个难度级别的混合数据\n",
    "    X_val, y_val = generate_mixed_data(num_samples=2000)\n",
    "    \n",
    "    # 将数据移到设备\n",
    "    X_train = X_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    X_val = X_val.to(device)\n",
    "    y_val = y_val.to(device)\n",
    "    \n",
    "    # 最终训练\n",
    "    for epoch in range(epochs_per_stage):\n",
    "        # 训练模式\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        indices = torch.randperm(len(X_train))\n",
    "        \n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            batch_indices = indices[i:i+batch_size]\n",
    "            inputs = X_train[batch_indices]\n",
    "            targets = y_train[batch_indices]\n",
    "            \n",
    "            # 前向传播\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        train_loss = total_loss / (len(X_train) / batch_size)\n",
    "        \n",
    "        # 验证\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val)\n",
    "            val_loss = criterion(val_outputs, y_val).item()\n",
    "            \n",
    "            # 计算准确率\n",
    "            _, val_predicted = torch.max(val_outputs, 1)\n",
    "            _, val_true_labels = torch.max(y_val, 1)\n",
    "            val_accuracy = (val_predicted == val_true_labels).float().mean().item()\n",
    "        \n",
    "        print(f'最终阶段 轮次 {epoch+1}/{epochs_per_stage}, '\n",
    "              f'训练损失: {train_loss:.4f}, 验证损失: {val_loss:.4f}, '\n",
    "              f'验证准确率: {val_accuracy:.4f}')\n",
    "    \n",
    "    # 保存最终模型\n",
    "    torch.save(model.state_dict(), \"model_final.pt\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始训练阶段 1: 10以内加法\n",
      "阶段 1 轮次 1/100, 训练损失: 0.7108, 验证损失: 0.6937, 验证准确率: 0.4970\n",
      "阶段 1 轮次 2/100, 训练损失: 0.7096, 验证损失: 0.6942, 验证准确率: 0.4960\n",
      "阶段 1 轮次 3/100, 训练损失: 0.7097, 验证损失: 0.6937, 验证准确率: 0.4960\n",
      "阶段 1 轮次 4/100, 训练损失: 0.7095, 验证损失: 0.6935, 验证准确率: 0.4970\n",
      "阶段 1 轮次 5/100, 训练损失: 0.7096, 验证损失: 0.6936, 验证准确率: 0.4960\n",
      "阶段 1 轮次 6/100, 训练损失: 0.7095, 验证损失: 0.6935, 验证准确率: 0.5040\n",
      "阶段 1 轮次 7/100, 训练损失: 0.7095, 验证损失: 0.6936, 验证准确率: 0.4960\n",
      "阶段 1 轮次 8/100, 训练损失: 0.7095, 验证损失: 0.6937, 验证准确率: 0.4960\n",
      "阶段 1 轮次 9/100, 训练损失: 0.7094, 验证损失: 0.6936, 验证准确率: 0.4960\n",
      "阶段 1 轮次 10/100, 训练损失: 0.7095, 验证损失: 0.6935, 验证准确率: 0.4970\n",
      "阶段 1 轮次 11/100, 训练损失: 0.7094, 验证损失: 0.6936, 验证准确率: 0.4960\n",
      "阶段 1 轮次 12/100, 训练损失: 0.7094, 验证损失: 0.6938, 验证准确率: 0.4960\n",
      "阶段 1 轮次 13/100, 训练损失: 0.7095, 验证损失: 0.6937, 验证准确率: 0.4950\n",
      "阶段 1 轮次 14/100, 训练损失: 0.7095, 验证损失: 0.6935, 验证准确率: 0.5050\n",
      "阶段 1 轮次 15/100, 训练损失: 0.7094, 验证损失: 0.6936, 验证准确率: 0.4950\n",
      "阶段 1 轮次 16/100, 训练损失: 0.7096, 验证损失: 0.6940, 验证准确率: 0.4950\n",
      "阶段 1 轮次 17/100, 训练损失: 0.7094, 验证损失: 0.6937, 验证准确率: 0.4960\n",
      "阶段 1 轮次 18/100, 训练损失: 0.7095, 验证损失: 0.6936, 验证准确率: 0.4970\n",
      "阶段 1 轮次 19/100, 训练损失: 0.7094, 验证损失: 0.6938, 验证准确率: 0.4950\n",
      "阶段 1 轮次 20/100, 训练损失: 0.7095, 验证损失: 0.6938, 验证准确率: 0.4950\n",
      "阶段 1 轮次 21/100, 训练损失: 0.7096, 验证损失: 0.6936, 验证准确率: 0.4840\n",
      "阶段 1 轮次 22/100, 训练损失: 0.7094, 验证损失: 0.6939, 验证准确率: 0.4950\n",
      "阶段 1 轮次 23/100, 训练损失: 0.7093, 验证损失: 0.6939, 验证准确率: 0.4950\n",
      "阶段 1 轮次 24/100, 训练损失: 0.7094, 验证损失: 0.6939, 验证准确率: 0.4950\n",
      "阶段 1 轮次 25/100, 训练损失: 0.7093, 验证损失: 0.6938, 验证准确率: 0.4970\n",
      "阶段 1 轮次 26/100, 训练损失: 0.7093, 验证损失: 0.6939, 验证准确率: 0.4950\n",
      "阶段 1 轮次 27/100, 训练损失: 0.7093, 验证损失: 0.6939, 验证准确率: 0.4950\n",
      "阶段 1 轮次 28/100, 训练损失: 0.7093, 验证损失: 0.6939, 验证准确率: 0.4960\n",
      "阶段 1 轮次 29/100, 训练损失: 0.7092, 验证损失: 0.6938, 验证准确率: 0.4960\n",
      "阶段 1 轮次 30/100, 训练损失: 0.7092, 验证损失: 0.6938, 验证准确率: 0.4990\n",
      "阶段 1 轮次 31/100, 训练损失: 0.7092, 验证损失: 0.6939, 验证准确率: 0.4950\n",
      "阶段 1 轮次 32/100, 训练损失: 0.7092, 验证损失: 0.6938, 验证准确率: 0.4950\n",
      "阶段 1 轮次 33/100, 训练损失: 0.7091, 验证损失: 0.6938, 验证准确率: 0.4950\n",
      "阶段 1 轮次 34/100, 训练损失: 0.7091, 验证损失: 0.6938, 验证准确率: 0.5040\n",
      "阶段 1 轮次 35/100, 训练损失: 0.7092, 验证损失: 0.6939, 验证准确率: 0.4940\n",
      "阶段 1 轮次 36/100, 训练损失: 0.7091, 验证损失: 0.6936, 验证准确率: 0.5050\n",
      "阶段 1 轮次 37/100, 训练损失: 0.7091, 验证损失: 0.6937, 验证准确率: 0.4960\n",
      "阶段 1 轮次 38/100, 训练损失: 0.7090, 验证损失: 0.6939, 验证准确率: 0.4940\n",
      "阶段 1 轮次 39/100, 训练损失: 0.7090, 验证损失: 0.6937, 验证准确率: 0.4990\n",
      "阶段 1 轮次 40/100, 训练损失: 0.7089, 验证损失: 0.6937, 验证准确率: 0.5000\n",
      "阶段 1 轮次 41/100, 训练损失: 0.7090, 验证损失: 0.6936, 验证准确率: 0.5050\n",
      "阶段 1 轮次 42/100, 训练损失: 0.7088, 验证损失: 0.6938, 验证准确率: 0.4950\n",
      "阶段 1 轮次 43/100, 训练损失: 0.7089, 验证损失: 0.6937, 验证准确率: 0.4960\n",
      "阶段 1 轮次 44/100, 训练损失: 0.7088, 验证损失: 0.6936, 验证准确率: 0.4980\n",
      "阶段 1 轮次 45/100, 训练损失: 0.7088, 验证损失: 0.6934, 验证准确率: 0.5120\n",
      "阶段 1 轮次 46/100, 训练损失: 0.7088, 验证损失: 0.6937, 验证准确率: 0.4960\n",
      "阶段 1 轮次 47/100, 训练损失: 0.7088, 验证损失: 0.6937, 验证准确率: 0.5020\n",
      "阶段 1 轮次 48/100, 训练损失: 0.7087, 验证损失: 0.6937, 验证准确率: 0.5170\n",
      "阶段 1 轮次 49/100, 训练损失: 0.7088, 验证损失: 0.6935, 验证准确率: 0.5020\n",
      "阶段 1 轮次 50/100, 训练损失: 0.7086, 验证损失: 0.6938, 验证准确率: 0.5030\n",
      "阶段 1 轮次 51/100, 训练损失: 0.7087, 验证损失: 0.6937, 验证准确率: 0.4980\n",
      "阶段 1 轮次 52/100, 训练损失: 0.7087, 验证损失: 0.6937, 验证准确率: 0.4960\n",
      "阶段 1 轮次 53/100, 训练损失: 0.7085, 验证损失: 0.6935, 验证准确率: 0.5210\n",
      "阶段 1 轮次 54/100, 训练损失: 0.7085, 验证损失: 0.6934, 验证准确率: 0.5150\n",
      "阶段 1 轮次 55/100, 训练损失: 0.7085, 验证损失: 0.6935, 验证准确率: 0.5180\n",
      "阶段 1 轮次 56/100, 训练损失: 0.7084, 验证损失: 0.6934, 验证准确率: 0.5140\n",
      "阶段 1 轮次 57/100, 训练损失: 0.7084, 验证损失: 0.6936, 验证准确率: 0.4980\n",
      "阶段 1 轮次 58/100, 训练损失: 0.7083, 验证损失: 0.6935, 验证准确率: 0.5090\n",
      "阶段 1 轮次 59/100, 训练损失: 0.7083, 验证损失: 0.6933, 验证准确率: 0.5160\n",
      "阶段 1 轮次 60/100, 训练损失: 0.7082, 验证损失: 0.6934, 验证准确率: 0.5170\n",
      "阶段 1 轮次 61/100, 训练损失: 0.7083, 验证损失: 0.6935, 验证准确率: 0.5040\n",
      "阶段 1 轮次 62/100, 训练损失: 0.7084, 验证损失: 0.6937, 验证准确率: 0.5130\n",
      "阶段 1 轮次 63/100, 训练损失: 0.7084, 验证损失: 0.6933, 验证准确率: 0.5200\n",
      "阶段 1 轮次 64/100, 训练损失: 0.7082, 验证损失: 0.6932, 验证准确率: 0.5260\n",
      "阶段 1 轮次 65/100, 训练损失: 0.7082, 验证损失: 0.6934, 验证准确率: 0.5110\n",
      "阶段 1 轮次 66/100, 训练损失: 0.7080, 验证损失: 0.6933, 验证准确率: 0.5290\n",
      "阶段 1 轮次 67/100, 训练损失: 0.7081, 验证损失: 0.6933, 验证准确率: 0.5270\n",
      "阶段 1 轮次 68/100, 训练损失: 0.7080, 验证损失: 0.6931, 验证准确率: 0.5290\n",
      "阶段 1 轮次 69/100, 训练损失: 0.7079, 验证损失: 0.6932, 验证准确率: 0.5240\n",
      "阶段 1 轮次 70/100, 训练损失: 0.7080, 验证损失: 0.6934, 验证准确率: 0.5310\n",
      "阶段 1 轮次 71/100, 训练损失: 0.7080, 验证损失: 0.6934, 验证准确率: 0.5220\n",
      "阶段 1 轮次 72/100, 训练损失: 0.7079, 验证损失: 0.6934, 验证准确率: 0.5390\n",
      "阶段 1 轮次 73/100, 训练损失: 0.7079, 验证损失: 0.6932, 验证准确率: 0.5250\n",
      "阶段 1 轮次 74/100, 训练损失: 0.7077, 验证损失: 0.6931, 验证准确率: 0.5310\n",
      "阶段 1 轮次 75/100, 训练损失: 0.7076, 验证损失: 0.6931, 验证准确率: 0.5420\n",
      "阶段 1 轮次 76/100, 训练损失: 0.7077, 验证损失: 0.6933, 验证准确率: 0.5300\n",
      "阶段 1 轮次 77/100, 训练损失: 0.7077, 验证损失: 0.6932, 验证准确率: 0.5310\n",
      "阶段 1 轮次 78/100, 训练损失: 0.7075, 验证损失: 0.6928, 验证准确率: 0.5430\n",
      "阶段 1 轮次 79/100, 训练损失: 0.7075, 验证损失: 0.6930, 验证准确率: 0.5450\n",
      "阶段 1 轮次 80/100, 训练损失: 0.7076, 验证损失: 0.6933, 验证准确率: 0.5290\n",
      "阶段 1 轮次 81/100, 训练损失: 0.7074, 验证损失: 0.6930, 验证准确率: 0.5470\n",
      "阶段 1 轮次 82/100, 训练损失: 0.7074, 验证损失: 0.6927, 验证准确率: 0.5470\n",
      "阶段 1 轮次 83/100, 训练损失: 0.7073, 验证损失: 0.6930, 验证准确率: 0.5440\n",
      "阶段 1 轮次 84/100, 训练损失: 0.7073, 验证损失: 0.6929, 验证准确率: 0.5360\n",
      "阶段 1 轮次 85/100, 训练损失: 0.7073, 验证损失: 0.6928, 验证准确率: 0.5420\n",
      "阶段 1 轮次 86/100, 训练损失: 0.7072, 验证损失: 0.6926, 验证准确率: 0.5490\n",
      "阶段 1 轮次 87/100, 训练损失: 0.7072, 验证损失: 0.6928, 验证准确率: 0.5450\n",
      "阶段 1 轮次 88/100, 训练损失: 0.7073, 验证损失: 0.6933, 验证准确率: 0.5370\n",
      "阶段 1 轮次 89/100, 训练损失: 0.7074, 验证损失: 0.6933, 验证准确率: 0.5400\n",
      "阶段 1 轮次 90/100, 训练损失: 0.7076, 验证损失: 0.6935, 验证准确率: 0.5260\n",
      "阶段 1 轮次 91/100, 训练损失: 0.7073, 验证损失: 0.6927, 验证准确率: 0.5420\n",
      "阶段 1 轮次 92/100, 训练损失: 0.7070, 验证损失: 0.6926, 验证准确率: 0.5500\n",
      "阶段 1 轮次 93/100, 训练损失: 0.7069, 验证损失: 0.6927, 验证准确率: 0.5470\n",
      "阶段 1 轮次 94/100, 训练损失: 0.7070, 验证损失: 0.6929, 验证准确率: 0.5410\n",
      "阶段 1 轮次 95/100, 训练损失: 0.7071, 验证损失: 0.6932, 验证准确率: 0.5430\n",
      "阶段 1 轮次 96/100, 训练损失: 0.7071, 验证损失: 0.6928, 验证准确率: 0.5550\n",
      "阶段 1 轮次 97/100, 训练损失: 0.7068, 验证损失: 0.6927, 验证准确率: 0.5420\n",
      "阶段 1 轮次 98/100, 训练损失: 0.7068, 验证损失: 0.6928, 验证准确率: 0.5540\n",
      "阶段 1 轮次 99/100, 训练损失: 0.7068, 验证损失: 0.6925, 验证准确率: 0.5540\n",
      "阶段 1 轮次 100/100, 训练损失: 0.7065, 验证损失: 0.6924, 验证准确率: 0.5520\n",
      "\n",
      "开始训练阶段 2: 100以内加法\n",
      "阶段 2 轮次 1/100, 训练损失: 0.7111, 验证损失: 0.6923, 验证准确率: 0.5410\n",
      "阶段 2 轮次 2/100, 训练损失: 0.7107, 验证损失: 0.6916, 验证准确率: 0.5160\n",
      "阶段 2 轮次 3/100, 训练损失: 0.7097, 验证损失: 0.6925, 验证准确率: 0.4880\n",
      "阶段 2 轮次 4/100, 训练损失: 0.7089, 验证损失: 0.6917, 验证准确率: 0.4890\n",
      "阶段 2 轮次 5/100, 训练损失: 0.7088, 验证损失: 0.6910, 验证准确率: 0.5510\n",
      "阶段 2 轮次 6/100, 训练损失: 0.7086, 验证损失: 0.6910, 验证准确率: 0.5820\n",
      "阶段 2 轮次 7/100, 训练损失: 0.7084, 验证损失: 0.6911, 验证准确率: 0.5060\n",
      "阶段 2 轮次 8/100, 训练损失: 0.7083, 验证损失: 0.6912, 验证准确率: 0.5080\n",
      "阶段 2 轮次 9/100, 训练损失: 0.7085, 验证损失: 0.6908, 验证准确率: 0.5770\n",
      "阶段 2 轮次 10/100, 训练损失: 0.7086, 验证损失: 0.6908, 验证准确率: 0.5690\n",
      "阶段 2 轮次 11/100, 训练损失: 0.7087, 验证损失: 0.6908, 验证准确率: 0.4910\n",
      "阶段 2 轮次 12/100, 训练损失: 0.7090, 验证损失: 0.6907, 验证准确率: 0.6030\n",
      "阶段 2 轮次 13/100, 训练损失: 0.7096, 验证损失: 0.6922, 验证准确率: 0.4580\n",
      "阶段 2 轮次 14/100, 训练损失: 0.7090, 验证损失: 0.6906, 验证准确率: 0.5520\n",
      "阶段 2 轮次 15/100, 训练损失: 0.7085, 验证损失: 0.6911, 验证准确率: 0.5110\n",
      "阶段 2 轮次 16/100, 训练损失: 0.7083, 验证损失: 0.6909, 验证准确率: 0.5010\n",
      "阶段 2 轮次 17/100, 训练损失: 0.7080, 验证损失: 0.6906, 验证准确率: 0.5970\n",
      "阶段 2 轮次 18/100, 训练损失: 0.7083, 验证损失: 0.6905, 验证准确率: 0.6120\n",
      "阶段 2 轮次 19/100, 训练损失: 0.7081, 验证损失: 0.6907, 验证准确率: 0.4940\n",
      "阶段 2 轮次 20/100, 训练损失: 0.7081, 验证损失: 0.6906, 验证准确率: 0.5790\n",
      "阶段 2 轮次 21/100, 训练损失: 0.7080, 验证损失: 0.6905, 验证准确率: 0.6070\n",
      "阶段 2 轮次 22/100, 训练损失: 0.7079, 验证损失: 0.6904, 验证准确率: 0.4760\n",
      "阶段 2 轮次 23/100, 训练损失: 0.7079, 验证损失: 0.6903, 验证准确率: 0.5310\n",
      "阶段 2 轮次 24/100, 训练损失: 0.7080, 验证损失: 0.6903, 验证准确率: 0.6170\n",
      "阶段 2 轮次 25/100, 训练损失: 0.7079, 验证损失: 0.6904, 验证准确率: 0.5530\n",
      "阶段 2 轮次 26/100, 训练损失: 0.7079, 验证损失: 0.6906, 验证准确率: 0.5760\n",
      "阶段 2 轮次 27/100, 训练损失: 0.7079, 验证损失: 0.6905, 验证准确率: 0.6050\n",
      "阶段 2 轮次 28/100, 训练损失: 0.7084, 验证损失: 0.6911, 验证准确率: 0.5650\n",
      "阶段 2 轮次 29/100, 训练损失: 0.7085, 验证损失: 0.6917, 验证准确率: 0.4510\n",
      "阶段 2 轮次 30/100, 训练损失: 0.7085, 验证损失: 0.6905, 验证准确率: 0.5800\n",
      "阶段 2 轮次 31/100, 训练损失: 0.7082, 验证损失: 0.6906, 验证准确率: 0.6060\n",
      "阶段 2 轮次 32/100, 训练损失: 0.7079, 验证损失: 0.6901, 验证准确率: 0.5650\n",
      "阶段 2 轮次 33/100, 训练损失: 0.7079, 验证损失: 0.6904, 验证准确率: 0.5430\n",
      "阶段 2 轮次 34/100, 训练损失: 0.7077, 验证损失: 0.6902, 验证准确率: 0.5370\n",
      "阶段 2 轮次 35/100, 训练损失: 0.7076, 验证损失: 0.6902, 验证准确率: 0.5430\n",
      "阶段 2 轮次 36/100, 训练损失: 0.7076, 验证损失: 0.6903, 验证准确率: 0.5670\n",
      "阶段 2 轮次 37/100, 训练损失: 0.7078, 验证损失: 0.6906, 验证准确率: 0.4810\n",
      "阶段 2 轮次 38/100, 训练损失: 0.7087, 验证损失: 0.6912, 验证准确率: 0.4920\n",
      "阶段 2 轮次 39/100, 训练损失: 0.7085, 验证损失: 0.6909, 验证准确率: 0.4460\n",
      "阶段 2 轮次 40/100, 训练损失: 0.7081, 验证损失: 0.6910, 验证准确率: 0.5050\n",
      "阶段 2 轮次 41/100, 训练损失: 0.7080, 验证损失: 0.6909, 验证准确率: 0.4270\n",
      "阶段 2 轮次 42/100, 训练损失: 0.7084, 验证损失: 0.6913, 验证准确率: 0.4950\n",
      "阶段 2 轮次 43/100, 训练损失: 0.7083, 验证损失: 0.6907, 验证准确率: 0.6180\n",
      "阶段 2 轮次 44/100, 训练损失: 0.7081, 验证损失: 0.6909, 验证准确率: 0.4880\n",
      "阶段 2 轮次 45/100, 训练损失: 0.7079, 验证损失: 0.6904, 验证准确率: 0.4400\n",
      "阶段 2 轮次 46/100, 训练损失: 0.7077, 验证损失: 0.6902, 验证准确率: 0.4610\n",
      "阶段 2 轮次 47/100, 训练损失: 0.7075, 验证损失: 0.6900, 验证准确率: 0.5730\n",
      "阶段 2 轮次 48/100, 训练损失: 0.7077, 验证损失: 0.6899, 验证准确率: 0.5880\n",
      "阶段 2 轮次 49/100, 训练损失: 0.7078, 验证损失: 0.6904, 验证准确率: 0.4980\n",
      "阶段 2 轮次 50/100, 训练损失: 0.7074, 验证损失: 0.6899, 验证准确率: 0.5880\n",
      "阶段 2 轮次 51/100, 训练损失: 0.7074, 验证损失: 0.6899, 验证准确率: 0.5860\n",
      "阶段 2 轮次 52/100, 训练损失: 0.7074, 验证损失: 0.6901, 验证准确率: 0.5660\n",
      "阶段 2 轮次 53/100, 训练损失: 0.7074, 验证损失: 0.6900, 验证准确率: 0.4760\n",
      "阶段 2 轮次 54/100, 训练损失: 0.7072, 验证损失: 0.6897, 验证准确率: 0.6070\n",
      "阶段 2 轮次 55/100, 训练损失: 0.7074, 验证损失: 0.6901, 验证准确率: 0.4550\n",
      "阶段 2 轮次 56/100, 训练损失: 0.7075, 验证损失: 0.6898, 验证准确率: 0.5740\n",
      "阶段 2 轮次 57/100, 训练损失: 0.7075, 验证损失: 0.6900, 验证准确率: 0.4980\n",
      "阶段 2 轮次 58/100, 训练损失: 0.7073, 验证损失: 0.6898, 验证准确率: 0.6120\n",
      "阶段 2 轮次 59/100, 训练损失: 0.7074, 验证损失: 0.6898, 验证准确率: 0.5760\n",
      "阶段 2 轮次 60/100, 训练损失: 0.7072, 验证损失: 0.6895, 验证准确率: 0.5990\n",
      "阶段 2 轮次 61/100, 训练损失: 0.7071, 验证损失: 0.6898, 验证准确率: 0.4740\n",
      "阶段 2 轮次 62/100, 训练损失: 0.7071, 验证损失: 0.6899, 验证准确率: 0.5220\n",
      "阶段 2 轮次 63/100, 训练损失: 0.7070, 验证损失: 0.6896, 验证准确率: 0.6170\n",
      "阶段 2 轮次 64/100, 训练损失: 0.7070, 验证损失: 0.6895, 验证准确率: 0.6110\n",
      "阶段 2 轮次 65/100, 训练损失: 0.7071, 验证损失: 0.6898, 验证准确率: 0.5660\n",
      "阶段 2 轮次 66/100, 训练损失: 0.7069, 验证损失: 0.6895, 验证准确率: 0.5970\n",
      "阶段 2 轮次 67/100, 训练损失: 0.7069, 验证损失: 0.6894, 验证准确率: 0.6140\n",
      "阶段 2 轮次 68/100, 训练损失: 0.7068, 验证损失: 0.6897, 验证准确率: 0.5580\n",
      "阶段 2 轮次 69/100, 训练损失: 0.7068, 验证损失: 0.6894, 验证准确率: 0.6160\n",
      "阶段 2 轮次 70/100, 训练损失: 0.7068, 验证损失: 0.6894, 验证准确率: 0.5910\n",
      "阶段 2 轮次 71/100, 训练损失: 0.7068, 验证损失: 0.6896, 验证准确率: 0.6190\n",
      "阶段 2 轮次 72/100, 训练损失: 0.7070, 验证损失: 0.6894, 验证准确率: 0.6090\n",
      "阶段 2 轮次 73/100, 训练损失: 0.7072, 验证损失: 0.6897, 验证准确率: 0.6060\n",
      "阶段 2 轮次 74/100, 训练损失: 0.7075, 验证损失: 0.6895, 验证准确率: 0.5710\n",
      "阶段 2 轮次 75/100, 训练损失: 0.7070, 验证损失: 0.6896, 验证准确率: 0.5130\n",
      "阶段 2 轮次 76/100, 训练损失: 0.7069, 验证损失: 0.6894, 验证准确率: 0.4790\n",
      "阶段 2 轮次 77/100, 训练损失: 0.7066, 验证损失: 0.6893, 验证准确率: 0.5240\n",
      "阶段 2 轮次 78/100, 训练损失: 0.7065, 验证损失: 0.6891, 验证准确率: 0.6210\n",
      "阶段 2 轮次 79/100, 训练损失: 0.7065, 验证损失: 0.6890, 验证准确率: 0.6150\n",
      "阶段 2 轮次 80/100, 训练损失: 0.7066, 验证损失: 0.6893, 验证准确率: 0.5860\n",
      "阶段 2 轮次 81/100, 训练损失: 0.7067, 验证损失: 0.6893, 验证准确率: 0.4760\n",
      "阶段 2 轮次 82/100, 训练损失: 0.7068, 验证损失: 0.6890, 验证准确率: 0.5910\n",
      "阶段 2 轮次 83/100, 训练损失: 0.7072, 验证损失: 0.6897, 验证准确率: 0.6030\n",
      "阶段 2 轮次 84/100, 训练损失: 0.7069, 验证损失: 0.6899, 验证准确率: 0.4300\n",
      "阶段 2 轮次 85/100, 训练损失: 0.7067, 验证损失: 0.6894, 验证准确率: 0.4610\n",
      "阶段 2 轮次 86/100, 训练损失: 0.7066, 验证损失: 0.6899, 验证准确率: 0.5490\n",
      "阶段 2 轮次 87/100, 训练损失: 0.7070, 验证损失: 0.6908, 验证准确率: 0.4300\n",
      "阶段 2 轮次 88/100, 训练损失: 0.7071, 验证损失: 0.6900, 验证准确率: 0.4330\n",
      "阶段 2 轮次 89/100, 训练损失: 0.7067, 验证损失: 0.6892, 验证准确率: 0.4800\n",
      "阶段 2 轮次 90/100, 训练损失: 0.7062, 验证损失: 0.6887, 验证准确率: 0.6170\n",
      "阶段 2 轮次 91/100, 训练损失: 0.7062, 验证损失: 0.6887, 验证准确率: 0.6150\n",
      "阶段 2 轮次 92/100, 训练损失: 0.7062, 验证损失: 0.6892, 验证准确率: 0.4420\n",
      "阶段 2 轮次 93/100, 训练损失: 0.7062, 验证损失: 0.6888, 验证准确率: 0.6410\n",
      "阶段 2 轮次 94/100, 训练损失: 0.7060, 验证损失: 0.6886, 验证准确率: 0.6190\n",
      "阶段 2 轮次 95/100, 训练损失: 0.7060, 验证损失: 0.6888, 验证准确率: 0.5520\n",
      "阶段 2 轮次 96/100, 训练损失: 0.7060, 验证损失: 0.6889, 验证准确率: 0.6120\n",
      "阶段 2 轮次 97/100, 训练损失: 0.7063, 验证损失: 0.6901, 验证准确率: 0.4280\n",
      "阶段 2 轮次 98/100, 训练损失: 0.7069, 验证损失: 0.6898, 验证准确率: 0.4540\n",
      "阶段 2 轮次 99/100, 训练损失: 0.7072, 验证损失: 0.6891, 验证准确率: 0.6210\n",
      "阶段 2 轮次 100/100, 训练损失: 0.7067, 验证损失: 0.6891, 验证准确率: 0.6440\n",
      "\n",
      "开始训练阶段 3: 1000以内加法\n",
      "阶段 3 轮次 1/100, 训练损失: 0.7111, 验证损失: 0.6941, 验证准确率: 0.5520\n",
      "阶段 3 轮次 2/100, 训练损失: 0.7089, 验证损失: 0.6922, 验证准确率: 0.4500\n",
      "阶段 3 轮次 3/100, 训练损失: 0.7079, 验证损失: 0.6915, 验证准确率: 0.5090\n",
      "阶段 3 轮次 4/100, 训练损失: 0.7078, 验证损失: 0.6909, 验证准确率: 0.5090\n",
      "阶段 3 轮次 5/100, 训练损失: 0.7075, 验证损失: 0.6907, 验证准确率: 0.4490\n",
      "阶段 3 轮次 6/100, 训练损失: 0.7073, 验证损失: 0.6915, 验证准确率: 0.5100\n",
      "阶段 3 轮次 7/100, 训练损失: 0.7081, 验证损失: 0.6911, 验证准确率: 0.4880\n",
      "阶段 3 轮次 8/100, 训练损失: 0.7077, 验证损失: 0.6913, 验证准确率: 0.5100\n",
      "阶段 3 轮次 9/100, 训练损失: 0.7075, 验证损失: 0.6908, 验证准确率: 0.4890\n",
      "阶段 3 轮次 10/100, 训练损失: 0.7073, 验证损失: 0.6904, 验证准确率: 0.5100\n",
      "阶段 3 轮次 11/100, 训练损失: 0.7077, 验证损失: 0.6907, 验证准确率: 0.5090\n",
      "阶段 3 轮次 12/100, 训练损失: 0.7081, 验证损失: 0.6914, 验证准确率: 0.5030\n",
      "阶段 3 轮次 13/100, 训练损失: 0.7077, 验证损失: 0.6914, 验证准确率: 0.4880\n",
      "阶段 3 轮次 14/100, 训练损失: 0.7079, 验证损失: 0.6911, 验证准确率: 0.5090\n",
      "阶段 3 轮次 15/100, 训练损失: 0.7073, 验证损失: 0.6905, 验证准确率: 0.5010\n",
      "阶段 3 轮次 16/100, 训练损失: 0.7073, 验证损失: 0.6905, 验证准确率: 0.5060\n",
      "阶段 3 轮次 17/100, 训练损失: 0.7069, 验证损失: 0.6899, 验证准确率: 0.5010\n",
      "阶段 3 轮次 18/100, 训练损失: 0.7072, 验证损失: 0.6907, 验证准确率: 0.4580\n",
      "阶段 3 轮次 19/100, 训练损失: 0.7071, 验证损失: 0.6899, 验证准确率: 0.4920\n",
      "阶段 3 轮次 20/100, 训练损失: 0.7069, 验证损失: 0.6902, 验证准确率: 0.5090\n",
      "阶段 3 轮次 21/100, 训练损失: 0.7069, 验证损失: 0.6907, 验证准确率: 0.5090\n",
      "阶段 3 轮次 22/100, 训练损失: 0.7074, 验证损失: 0.6899, 验证准确率: 0.5020\n",
      "阶段 3 轮次 23/100, 训练损失: 0.7070, 验证损失: 0.6900, 验证准确率: 0.4940\n",
      "阶段 3 轮次 24/100, 训练损失: 0.7071, 验证损失: 0.6909, 验证准确率: 0.4980\n",
      "阶段 3 轮次 25/100, 训练损失: 0.7075, 验证损失: 0.6916, 验证准确率: 0.5120\n",
      "阶段 3 轮次 26/100, 训练损失: 0.7083, 验证损失: 0.6902, 验证准确率: 0.4770\n",
      "阶段 3 轮次 27/100, 训练损失: 0.7087, 验证损失: 0.6918, 验证准确率: 0.5030\n",
      "阶段 3 轮次 28/100, 训练损失: 0.7074, 验证损失: 0.6907, 验证准确率: 0.5080\n",
      "阶段 3 轮次 29/100, 训练损失: 0.7069, 验证损失: 0.6900, 验证准确率: 0.5080\n",
      "阶段 3 轮次 30/100, 训练损失: 0.7075, 验证损失: 0.6900, 验证准确率: 0.5030\n",
      "阶段 3 轮次 31/100, 训练损失: 0.7071, 验证损失: 0.6905, 验证准确率: 0.5180\n",
      "阶段 3 轮次 32/100, 训练损失: 0.7073, 验证损失: 0.6901, 验证准确率: 0.5000\n",
      "阶段 3 轮次 33/100, 训练损失: 0.7069, 验证损失: 0.6905, 验证准确率: 0.4230\n",
      "阶段 3 轮次 34/100, 训练损失: 0.7069, 验证损失: 0.6896, 验证准确率: 0.5040\n",
      "阶段 3 轮次 35/100, 训练损失: 0.7075, 验证损失: 0.6901, 验证准确率: 0.4960\n",
      "阶段 3 轮次 36/100, 训练损失: 0.7081, 验证损失: 0.6920, 验证准确率: 0.5770\n",
      "阶段 3 轮次 37/100, 训练损失: 0.7082, 验证损失: 0.6916, 验证准确率: 0.5090\n",
      "阶段 3 轮次 38/100, 训练损失: 0.7073, 验证损失: 0.6913, 验证准确率: 0.5010\n",
      "阶段 3 轮次 39/100, 训练损失: 0.7074, 验证损失: 0.6913, 验证准确率: 0.4250\n",
      "阶段 3 轮次 40/100, 训练损失: 0.7074, 验证损失: 0.6907, 验证准确率: 0.5000\n",
      "阶段 3 轮次 41/100, 训练损失: 0.7072, 验证损失: 0.6901, 验证准确率: 0.5110\n",
      "阶段 3 轮次 42/100, 训练损失: 0.7074, 验证损失: 0.6913, 验证准确率: 0.4830\n",
      "阶段 3 轮次 43/100, 训练损失: 0.7077, 验证损失: 0.6916, 验证准确率: 0.4750\n",
      "阶段 3 轮次 44/100, 训练损失: 0.7073, 验证损失: 0.6904, 验证准确率: 0.5080\n",
      "阶段 3 轮次 45/100, 训练损失: 0.7069, 验证损失: 0.6901, 验证准确率: 0.5080\n",
      "阶段 3 轮次 46/100, 训练损失: 0.7070, 验证损失: 0.6900, 验证准确率: 0.4730\n",
      "阶段 3 轮次 47/100, 训练损失: 0.7065, 验证损失: 0.6900, 验证准确率: 0.4500\n",
      "阶段 3 轮次 48/100, 训练损失: 0.7068, 验证损失: 0.6907, 验证准确率: 0.5090\n",
      "阶段 3 轮次 49/100, 训练损失: 0.7069, 验证损失: 0.6900, 验证准确率: 0.5090\n",
      "阶段 3 轮次 50/100, 训练损失: 0.7076, 验证损失: 0.6898, 验证准确率: 0.5040\n",
      "阶段 3 轮次 51/100, 训练损失: 0.7078, 验证损失: 0.6917, 验证准确率: 0.5450\n",
      "阶段 3 轮次 52/100, 训练损失: 0.7078, 验证损失: 0.6907, 验证准确率: 0.5590\n",
      "阶段 3 轮次 53/100, 训练损失: 0.7073, 验证损失: 0.6904, 验证准确率: 0.5040\n",
      "阶段 3 轮次 54/100, 训练损失: 0.7074, 验证损失: 0.6919, 验证准确率: 0.4910\n",
      "阶段 3 轮次 55/100, 训练损失: 0.7077, 验证损失: 0.6907, 验证准确率: 0.5160\n",
      "阶段 3 轮次 56/100, 训练损失: 0.7070, 验证损失: 0.6900, 验证准确率: 0.4980\n",
      "阶段 3 轮次 57/100, 训练损失: 0.7069, 验证损失: 0.6902, 验证准确率: 0.5060\n",
      "阶段 3 轮次 58/100, 训练损失: 0.7065, 验证损失: 0.6897, 验证准确率: 0.5050\n",
      "阶段 3 轮次 59/100, 训练损失: 0.7063, 验证损失: 0.6895, 验证准确率: 0.4830\n",
      "阶段 3 轮次 60/100, 训练损失: 0.7067, 验证损失: 0.6904, 验证准确率: 0.4460\n",
      "阶段 3 轮次 61/100, 训练损失: 0.7067, 验证损失: 0.6894, 验证准确率: 0.5010\n",
      "阶段 3 轮次 62/100, 训练损失: 0.7062, 验证损失: 0.6898, 验证准确率: 0.5000\n",
      "阶段 3 轮次 63/100, 训练损失: 0.7065, 验证损失: 0.6896, 验证准确率: 0.4960\n",
      "阶段 3 轮次 64/100, 训练损失: 0.7063, 验证损失: 0.6899, 验证准确率: 0.5010\n",
      "阶段 3 轮次 65/100, 训练损失: 0.7061, 验证损失: 0.6897, 验证准确率: 0.5130\n",
      "阶段 3 轮次 66/100, 训练损失: 0.7062, 验证损失: 0.6899, 验证准确率: 0.4910\n",
      "阶段 3 轮次 67/100, 训练损失: 0.7063, 验证损失: 0.6892, 验证准确率: 0.4900\n",
      "阶段 3 轮次 68/100, 训练损失: 0.7058, 验证损失: 0.6895, 验证准确率: 0.4980\n",
      "阶段 3 轮次 69/100, 训练损失: 0.7061, 验证损失: 0.6901, 验证准确率: 0.4570\n",
      "阶段 3 轮次 70/100, 训练损失: 0.7062, 验证损失: 0.6890, 验证准确率: 0.4910\n",
      "阶段 3 轮次 71/100, 训练损失: 0.7059, 验证损失: 0.6899, 验证准确率: 0.5060\n",
      "阶段 3 轮次 72/100, 训练损失: 0.7061, 验证损失: 0.6895, 验证准确率: 0.5060\n",
      "阶段 3 轮次 73/100, 训练损失: 0.7059, 验证损失: 0.6896, 验证准确率: 0.5200\n",
      "阶段 3 轮次 74/100, 训练损失: 0.7060, 验证损失: 0.6899, 验证准确率: 0.5040\n",
      "阶段 3 轮次 75/100, 训练损失: 0.7065, 验证损失: 0.6901, 验证准确率: 0.5320\n",
      "阶段 3 轮次 76/100, 训练损失: 0.7067, 验证损失: 0.6911, 验证准确率: 0.5340\n",
      "阶段 3 轮次 77/100, 训练损失: 0.7068, 验证损失: 0.6903, 验证准确率: 0.5250\n",
      "阶段 3 轮次 78/100, 训练损失: 0.7070, 验证损失: 0.6898, 验证准确率: 0.5020\n",
      "阶段 3 轮次 79/100, 训练损失: 0.7060, 验证损失: 0.6891, 验证准确率: 0.4820\n",
      "阶段 3 轮次 80/100, 训练损失: 0.7057, 验证损失: 0.6895, 验证准确率: 0.5050\n",
      "阶段 3 轮次 81/100, 训练损失: 0.7058, 验证损失: 0.6898, 验证准确率: 0.4940\n",
      "阶段 3 轮次 82/100, 训练损失: 0.7059, 验证损失: 0.6899, 验证准确率: 0.5290\n",
      "阶段 3 轮次 83/100, 训练损失: 0.7063, 验证损失: 0.6898, 验证准确率: 0.4640\n",
      "阶段 3 轮次 84/100, 训练损失: 0.7056, 验证损失: 0.6886, 验证准确率: 0.5040\n",
      "阶段 3 轮次 85/100, 训练损失: 0.7056, 验证损失: 0.6892, 验证准确率: 0.4930\n",
      "阶段 3 轮次 86/100, 训练损失: 0.7054, 验证损失: 0.6885, 验证准确率: 0.4950\n",
      "阶段 3 轮次 87/100, 训练损失: 0.7053, 验证损失: 0.6885, 验证准确率: 0.5080\n",
      "阶段 3 轮次 88/100, 训练损失: 0.7054, 验证损失: 0.6891, 验证准确率: 0.5350\n",
      "阶段 3 轮次 89/100, 训练损失: 0.7053, 验证损失: 0.6887, 验证准确率: 0.5260\n",
      "阶段 3 轮次 90/100, 训练损失: 0.7053, 验证损失: 0.6895, 验证准确率: 0.5020\n",
      "阶段 3 轮次 91/100, 训练损失: 0.7055, 验证损失: 0.6896, 验证准确率: 0.5010\n",
      "阶段 3 轮次 92/100, 训练损失: 0.7055, 验证损失: 0.6886, 验证准确率: 0.5090\n",
      "阶段 3 轮次 93/100, 训练损失: 0.7053, 验证损失: 0.6886, 验证准确率: 0.4750\n",
      "阶段 3 轮次 94/100, 训练损失: 0.7056, 验证损失: 0.6897, 验证准确率: 0.5080\n",
      "阶段 3 轮次 95/100, 训练损失: 0.7059, 验证损失: 0.6891, 验证准确率: 0.4920\n",
      "阶段 3 轮次 96/100, 训练损失: 0.7054, 验证损失: 0.6882, 验证准确率: 0.5030\n",
      "阶段 3 轮次 97/100, 训练损失: 0.7050, 验证损失: 0.6885, 验证准确率: 0.4910\n",
      "阶段 3 轮次 98/100, 训练损失: 0.7050, 验证损失: 0.6887, 验证准确率: 0.5180\n",
      "阶段 3 轮次 99/100, 训练损失: 0.7052, 验证损失: 0.6890, 验证准确率: 0.5500\n",
      "阶段 3 轮次 100/100, 训练损失: 0.7052, 验证损失: 0.6884, 验证准确率: 0.5190\n",
      "\n",
      "开始训练阶段 4: 10000以内加法\n",
      "阶段 4 轮次 1/100, 训练损失: 0.7090, 验证损失: 0.6931, 验证准确率: 0.5150\n",
      "阶段 4 轮次 2/100, 训练损失: 0.7098, 验证损失: 0.6931, 验证准确率: 0.5460\n",
      "阶段 4 轮次 3/100, 训练损失: 0.7089, 验证损失: 0.6937, 验证准确率: 0.4750\n",
      "阶段 4 轮次 4/100, 训练损失: 0.7079, 验证损失: 0.6922, 验证准确率: 0.4580\n",
      "阶段 4 轮次 5/100, 训练损失: 0.7083, 验证损失: 0.6909, 验证准确率: 0.5680\n",
      "阶段 4 轮次 6/100, 训练损失: 0.7074, 验证损失: 0.6911, 验证准确率: 0.5630\n",
      "阶段 4 轮次 7/100, 训练损失: 0.7067, 验证损失: 0.6915, 验证准确率: 0.4860\n",
      "阶段 4 轮次 8/100, 训练损失: 0.7064, 验证损失: 0.6907, 验证准确率: 0.6040\n",
      "阶段 4 轮次 9/100, 训练损失: 0.7062, 验证损失: 0.6911, 验证准确率: 0.5190\n",
      "阶段 4 轮次 10/100, 训练损失: 0.7061, 验证损失: 0.6912, 验证准确率: 0.4820\n",
      "阶段 4 轮次 11/100, 训练损失: 0.7061, 验证损失: 0.6911, 验证准确率: 0.4900\n",
      "阶段 4 轮次 12/100, 训练损失: 0.7064, 验证损失: 0.6916, 验证准确率: 0.5460\n",
      "阶段 4 轮次 13/100, 训练损失: 0.7067, 验证损失: 0.6913, 验证准确率: 0.4900\n",
      "阶段 4 轮次 14/100, 训练损失: 0.7063, 验证损失: 0.6907, 验证准确率: 0.5630\n",
      "阶段 4 轮次 15/100, 训练损失: 0.7063, 验证损失: 0.6926, 验证准确率: 0.4930\n",
      "阶段 4 轮次 16/100, 训练损失: 0.7070, 验证损失: 0.6925, 验证准确率: 0.4880\n",
      "阶段 4 轮次 17/100, 训练损失: 0.7067, 验证损失: 0.6911, 验证准确率: 0.5830\n",
      "阶段 4 轮次 18/100, 训练损失: 0.7065, 验证损失: 0.6915, 验证准确率: 0.4400\n",
      "阶段 4 轮次 19/100, 训练损失: 0.7064, 验证损失: 0.6912, 验证准确率: 0.4830\n",
      "阶段 4 轮次 20/100, 训练损失: 0.7060, 验证损失: 0.6912, 验证准确率: 0.5310\n",
      "阶段 4 轮次 21/100, 训练损失: 0.7059, 验证损失: 0.6906, 验证准确率: 0.5850\n",
      "阶段 4 轮次 22/100, 训练损失: 0.7059, 验证损失: 0.6910, 验证准确率: 0.5160\n",
      "阶段 4 轮次 23/100, 训练损失: 0.7059, 验证损失: 0.6909, 验证准确率: 0.5470\n",
      "阶段 4 轮次 24/100, 训练损失: 0.7059, 验证损失: 0.6906, 验证准确率: 0.5660\n",
      "阶段 4 轮次 25/100, 训练损失: 0.7057, 验证损失: 0.6913, 验证准确率: 0.4910\n",
      "阶段 4 轮次 26/100, 训练损失: 0.7061, 验证损失: 0.6913, 验证准确率: 0.5410\n",
      "阶段 4 轮次 27/100, 训练损失: 0.7062, 验证损失: 0.6921, 验证准确率: 0.5380\n",
      "阶段 4 轮次 28/100, 训练损失: 0.7072, 验证损失: 0.6924, 验证准确率: 0.4230\n",
      "阶段 4 轮次 29/100, 训练损失: 0.7066, 验证损失: 0.6910, 验证准确率: 0.5560\n",
      "阶段 4 轮次 30/100, 训练损失: 0.7061, 验证损失: 0.6920, 验证准确率: 0.4550\n",
      "阶段 4 轮次 31/100, 训练损失: 0.7066, 验证损失: 0.6910, 验证准确率: 0.4670\n",
      "阶段 4 轮次 32/100, 训练损失: 0.7071, 验证损失: 0.6929, 验证准确率: 0.4750\n",
      "阶段 4 轮次 33/100, 训练损失: 0.7078, 验证损失: 0.6916, 验证准确率: 0.5520\n",
      "阶段 4 轮次 34/100, 训练损失: 0.7067, 验证损失: 0.6909, 验证准确率: 0.5250\n",
      "阶段 4 轮次 35/100, 训练损失: 0.7061, 验证损失: 0.6905, 验证准确率: 0.5860\n",
      "阶段 4 轮次 36/100, 训练损失: 0.7059, 验证损失: 0.6907, 验证准确率: 0.5930\n",
      "阶段 4 轮次 37/100, 训练损失: 0.7057, 验证损失: 0.6907, 验证准确率: 0.5400\n",
      "阶段 4 轮次 38/100, 训练损失: 0.7057, 验证损失: 0.6909, 验证准确率: 0.4880\n",
      "阶段 4 轮次 39/100, 训练损失: 0.7059, 验证损失: 0.6908, 验证准确率: 0.5850\n",
      "阶段 4 轮次 40/100, 训练损失: 0.7056, 验证损失: 0.6907, 验证准确率: 0.5010\n",
      "阶段 4 轮次 41/100, 训练损失: 0.7054, 验证损失: 0.6904, 验证准确率: 0.5690\n",
      "阶段 4 轮次 42/100, 训练损失: 0.7057, 验证损失: 0.6904, 验证准确率: 0.5730\n",
      "阶段 4 轮次 43/100, 训练损失: 0.7057, 验证损失: 0.6908, 验证准确率: 0.5090\n",
      "阶段 4 轮次 44/100, 训练损失: 0.7059, 验证损失: 0.6928, 验证准确率: 0.4570\n",
      "阶段 4 轮次 45/100, 训练损失: 0.7063, 验证损失: 0.6911, 验证准确率: 0.4560\n",
      "阶段 4 轮次 46/100, 训练损失: 0.7058, 验证损失: 0.6911, 验证准确率: 0.5500\n",
      "阶段 4 轮次 47/100, 训练损失: 0.7058, 验证损失: 0.6905, 验证准确率: 0.5860\n",
      "阶段 4 轮次 48/100, 训练损失: 0.7061, 验证损失: 0.6920, 验证准确率: 0.5330\n",
      "阶段 4 轮次 49/100, 训练损失: 0.7063, 验证损失: 0.6916, 验证准确率: 0.4210\n",
      "阶段 4 轮次 50/100, 训练损失: 0.7062, 验证损失: 0.6907, 验证准确率: 0.5740\n",
      "阶段 4 轮次 51/100, 训练损失: 0.7059, 验证损失: 0.6916, 验证准确率: 0.5440\n",
      "阶段 4 轮次 52/100, 训练损失: 0.7059, 验证损失: 0.6910, 验证准确率: 0.5330\n",
      "阶段 4 轮次 53/100, 训练损失: 0.7057, 验证损失: 0.6898, 验证准确率: 0.6050\n",
      "阶段 4 轮次 54/100, 训练损失: 0.7055, 验证损失: 0.6908, 验证准确率: 0.5240\n",
      "阶段 4 轮次 55/100, 训练损失: 0.7056, 验证损失: 0.6904, 验证准确率: 0.5630\n",
      "阶段 4 轮次 56/100, 训练损失: 0.7052, 验证损失: 0.6902, 验证准确率: 0.6100\n",
      "阶段 4 轮次 57/100, 训练损失: 0.7051, 验证损失: 0.6904, 验证准确率: 0.5640\n",
      "阶段 4 轮次 58/100, 训练损失: 0.7055, 验证损失: 0.6904, 验证准确率: 0.5740\n",
      "阶段 4 轮次 59/100, 训练损失: 0.7052, 验证损失: 0.6909, 验证准确率: 0.4450\n",
      "阶段 4 轮次 60/100, 训练损失: 0.7052, 验证损失: 0.6913, 验证准确率: 0.4740\n",
      "阶段 4 轮次 61/100, 训练损失: 0.7059, 验证损失: 0.6905, 验证准确率: 0.6090\n",
      "阶段 4 轮次 62/100, 训练损失: 0.7053, 验证损失: 0.6904, 验证准确率: 0.5700\n",
      "阶段 4 轮次 63/100, 训练损失: 0.7050, 验证损失: 0.6902, 验证准确率: 0.5800\n",
      "阶段 4 轮次 64/100, 训练损失: 0.7058, 验证损失: 0.6907, 验证准确率: 0.5110\n",
      "阶段 4 轮次 65/100, 训练损失: 0.7055, 验证损失: 0.6913, 验证准确率: 0.5610\n",
      "阶段 4 轮次 66/100, 训练损失: 0.7057, 验证损失: 0.6914, 验证准确率: 0.4730\n",
      "阶段 4 轮次 67/100, 训练损失: 0.7053, 验证损失: 0.6901, 验证准确率: 0.5840\n",
      "阶段 4 轮次 68/100, 训练损失: 0.7055, 验证损失: 0.6913, 验证准确率: 0.5700\n",
      "阶段 4 轮次 69/100, 训练损失: 0.7062, 验证损失: 0.6912, 验证准确率: 0.5740\n",
      "阶段 4 轮次 70/100, 训练损失: 0.7061, 验证损失: 0.6915, 验证准确率: 0.5460\n",
      "阶段 4 轮次 71/100, 训练损失: 0.7057, 验证损失: 0.6917, 验证准确率: 0.4440\n",
      "阶段 4 轮次 72/100, 训练损失: 0.7058, 验证损失: 0.6906, 验证准确率: 0.5220\n",
      "阶段 4 轮次 73/100, 训练损失: 0.7055, 验证损失: 0.6903, 验证准确率: 0.5690\n",
      "阶段 4 轮次 74/100, 训练损失: 0.7050, 验证损失: 0.6902, 验证准确率: 0.5530\n",
      "阶段 4 轮次 75/100, 训练损失: 0.7052, 验证损失: 0.6920, 验证准确率: 0.4560\n",
      "阶段 4 轮次 76/100, 训练损失: 0.7056, 验证损失: 0.6910, 验证准确率: 0.4760\n",
      "阶段 4 轮次 77/100, 训练损失: 0.7056, 验证损失: 0.6908, 验证准确率: 0.5640\n",
      "阶段 4 轮次 78/100, 训练损失: 0.7053, 验证损失: 0.6903, 验证准确率: 0.6170\n",
      "阶段 4 轮次 79/100, 训练损失: 0.7055, 验证损失: 0.6898, 验证准确率: 0.6020\n",
      "阶段 4 轮次 80/100, 训练损失: 0.7050, 验证损失: 0.6909, 验证准确率: 0.5220\n",
      "阶段 4 轮次 81/100, 训练损失: 0.7052, 验证损失: 0.6912, 验证准确率: 0.5480\n",
      "阶段 4 轮次 82/100, 训练损失: 0.7057, 验证损失: 0.6901, 验证准确率: 0.6000\n",
      "阶段 4 轮次 83/100, 训练损失: 0.7063, 验证损失: 0.6921, 验证准确率: 0.5540\n",
      "阶段 4 轮次 84/100, 训练损失: 0.7063, 验证损失: 0.6898, 验证准确率: 0.5460\n",
      "阶段 4 轮次 85/100, 训练损失: 0.7055, 验证损失: 0.6898, 验证准确率: 0.6130\n",
      "阶段 4 轮次 86/100, 训练损失: 0.7050, 验证损失: 0.6906, 验证准确率: 0.5070\n",
      "阶段 4 轮次 87/100, 训练损失: 0.7050, 验证损失: 0.6906, 验证准确率: 0.4780\n",
      "阶段 4 轮次 88/100, 训练损失: 0.7050, 验证损失: 0.6899, 验证准确率: 0.5810\n",
      "阶段 4 轮次 89/100, 训练损失: 0.7050, 验证损失: 0.6915, 验证准确率: 0.4810\n",
      "阶段 4 轮次 90/100, 训练损失: 0.7052, 验证损失: 0.6904, 验证准确率: 0.5640\n",
      "阶段 4 轮次 91/100, 训练损失: 0.7047, 验证损失: 0.6898, 验证准确率: 0.6150\n",
      "阶段 4 轮次 92/100, 训练损失: 0.7046, 验证损失: 0.6900, 验证准确率: 0.5900\n",
      "阶段 4 轮次 93/100, 训练损失: 0.7045, 验证损失: 0.6906, 验证准确率: 0.4700\n",
      "阶段 4 轮次 94/100, 训练损失: 0.7052, 验证损失: 0.6906, 验证准确率: 0.5900\n",
      "阶段 4 轮次 95/100, 训练损失: 0.7052, 验证损失: 0.6902, 验证准确率: 0.6040\n",
      "阶段 4 轮次 96/100, 训练损失: 0.7049, 验证损失: 0.6904, 验证准确率: 0.5720\n",
      "阶段 4 轮次 97/100, 训练损失: 0.7051, 验证损失: 0.6914, 验证准确率: 0.5350\n",
      "阶段 4 轮次 98/100, 训练损失: 0.7050, 验证损失: 0.6897, 验证准确率: 0.5680\n",
      "阶段 4 轮次 99/100, 训练损失: 0.7044, 验证损失: 0.6896, 验证准确率: 0.6200\n",
      "阶段 4 轮次 100/100, 训练损失: 0.7045, 验证损失: 0.6901, 验证准确率: 0.5000\n",
      "\n",
      "开始最终整合阶段: 混合数据训练\n",
      "最终阶段 轮次 1/100, 训练损失: 0.6906, 验证损失: 0.6884, 验证准确率: 0.6413\n",
      "最终阶段 轮次 2/100, 训练损失: 0.6893, 验证损失: 0.6872, 验证准确率: 0.6823\n",
      "最终阶段 轮次 3/100, 训练损失: 0.6881, 验证损失: 0.6862, 验证准确率: 0.5950\n",
      "最终阶段 轮次 4/100, 训练损失: 0.6873, 验证损失: 0.6853, 验证准确率: 0.6473\n",
      "最终阶段 轮次 5/100, 训练损失: 0.6860, 验证损失: 0.6833, 验证准确率: 0.6826\n",
      "最终阶段 轮次 6/100, 训练损失: 0.6839, 验证损失: 0.6834, 验证准确率: 0.4156\n",
      "最终阶段 轮次 7/100, 训练损失: 0.6823, 验证损失: 0.6834, 验证准确率: 0.6013\n",
      "最终阶段 轮次 8/100, 训练损失: 0.6801, 验证损失: 0.6785, 验证准确率: 0.6696\n",
      "最终阶段 轮次 9/100, 训练损失: 0.6784, 验证损失: 0.6785, 验证准确率: 0.6734\n",
      "最终阶段 轮次 10/100, 训练损失: 0.6767, 验证损失: 0.6736, 验证准确率: 0.6891\n",
      "最终阶段 轮次 11/100, 训练损失: 0.6741, 验证损失: 0.6736, 验证准确率: 0.6833\n",
      "最终阶段 轮次 12/100, 训练损失: 0.6724, 验证损失: 0.6694, 验证准确率: 0.6741\n",
      "最终阶段 轮次 13/100, 训练损失: 0.6695, 验证损失: 0.6712, 验证准确率: 0.6666\n",
      "最终阶段 轮次 14/100, 训练损失: 0.6673, 验证损失: 0.6632, 验证准确率: 0.6915\n",
      "最终阶段 轮次 15/100, 训练损失: 0.6642, 验证损失: 0.6614, 验证准确率: 0.6884\n",
      "最终阶段 轮次 16/100, 训练损失: 0.6621, 验证损失: 0.6587, 验证准确率: 0.6921\n",
      "最终阶段 轮次 17/100, 训练损失: 0.6593, 验证损失: 0.6554, 验证准确率: 0.7003\n",
      "最终阶段 轮次 18/100, 训练损失: 0.6553, 验证损失: 0.6517, 验证准确率: 0.7028\n",
      "最终阶段 轮次 19/100, 训练损失: 0.6534, 验证损失: 0.6490, 验证准确率: 0.6935\n",
      "最终阶段 轮次 20/100, 训练损失: 0.6498, 验证损失: 0.6465, 验证准确率: 0.6916\n",
      "最终阶段 轮次 21/100, 训练损失: 0.6473, 验证损失: 0.6423, 验证准确率: 0.7030\n",
      "最终阶段 轮次 22/100, 训练损失: 0.6431, 验证损失: 0.6399, 验证准确率: 0.7018\n",
      "最终阶段 轮次 23/100, 训练损失: 0.6411, 验证损失: 0.6363, 验证准确率: 0.7111\n",
      "最终阶段 轮次 24/100, 训练损失: 0.6365, 验证损失: 0.6445, 验证准确率: 0.5965\n",
      "最终阶段 轮次 25/100, 训练损失: 0.6339, 验证损失: 0.6482, 验证准确率: 0.5081\n",
      "最终阶段 轮次 26/100, 训练损失: 0.6289, 验证损失: 0.6230, 验证准确率: 0.7111\n",
      "最终阶段 轮次 27/100, 训练损失: 0.6253, 验证损失: 0.6215, 验证准确率: 0.6986\n",
      "最终阶段 轮次 28/100, 训练损失: 0.6197, 验证损失: 0.6140, 验证准确率: 0.7078\n",
      "最终阶段 轮次 29/100, 训练损失: 0.6139, 验证损失: 0.6126, 验证准确率: 0.7113\n",
      "最终阶段 轮次 30/100, 训练损失: 0.6110, 验证损失: 0.6039, 验证准确率: 0.7093\n",
      "最终阶段 轮次 31/100, 训练损失: 0.6077, 验证损失: 0.5988, 验证准确率: 0.7255\n",
      "最终阶段 轮次 32/100, 训练损失: 0.5996, 验证损失: 0.5959, 验证准确率: 0.7074\n",
      "最终阶段 轮次 33/100, 训练损失: 0.5941, 验证损失: 0.5902, 验证准确率: 0.7190\n",
      "最终阶段 轮次 34/100, 训练损失: 0.5911, 验证损失: 0.5848, 验证准确率: 0.7666\n",
      "最终阶段 轮次 35/100, 训练损失: 0.5838, 验证损失: 0.5858, 验证准确率: 0.7281\n",
      "最终阶段 轮次 36/100, 训练损失: 0.5778, 验证损失: 0.5821, 验证准确率: 0.7653\n",
      "最终阶段 轮次 37/100, 训练损失: 0.5724, 验证损失: 0.5680, 验证准确率: 0.7551\n",
      "最终阶段 轮次 38/100, 训练损失: 0.5654, 验证损失: 0.5581, 验证准确率: 0.8121\n",
      "最终阶段 轮次 39/100, 训练损失: 0.5590, 验证损失: 0.5532, 验证准确率: 0.8134\n",
      "最终阶段 轮次 40/100, 训练损失: 0.5516, 验证损失: 0.5562, 验证准确率: 0.8109\n",
      "最终阶段 轮次 41/100, 训练损失: 0.5477, 验证损失: 0.5445, 验证准确率: 0.8085\n",
      "最终阶段 轮次 42/100, 训练损失: 0.5394, 验证损失: 0.5309, 验证准确率: 0.8380\n",
      "最终阶段 轮次 43/100, 训练损失: 0.5283, 验证损失: 0.5307, 验证准确率: 0.8496\n",
      "最终阶段 轮次 44/100, 训练损失: 0.5222, 验证损失: 0.5158, 验证准确率: 0.8449\n",
      "最终阶段 轮次 45/100, 训练损失: 0.5113, 验证损失: 0.5077, 验证准确率: 0.8539\n",
      "最终阶段 轮次 46/100, 训练损失: 0.5034, 验证损失: 0.4934, 验证准确率: 0.8471\n",
      "最终阶段 轮次 47/100, 训练损失: 0.4943, 验证损失: 0.4855, 验证准确率: 0.8623\n",
      "最终阶段 轮次 48/100, 训练损失: 0.4837, 验证损失: 0.4799, 验证准确率: 0.8544\n",
      "最终阶段 轮次 49/100, 训练损失: 0.4818, 验证损失: 0.4707, 验证准确率: 0.8859\n",
      "最终阶段 轮次 50/100, 训练损失: 0.4678, 验证损失: 0.4612, 验证准确率: 0.8658\n",
      "最终阶段 轮次 51/100, 训练损失: 0.4589, 验证损失: 0.4514, 验证准确率: 0.8755\n",
      "最终阶段 轮次 52/100, 训练损失: 0.4507, 验证损失: 0.4440, 验证准确率: 0.8756\n",
      "最终阶段 轮次 53/100, 训练损失: 0.4425, 验证损失: 0.4389, 验证准确率: 0.8789\n",
      "最终阶段 轮次 54/100, 训练损失: 0.4381, 验证损失: 0.4267, 验证准确率: 0.8820\n",
      "最终阶段 轮次 55/100, 训练损失: 0.4277, 验证损失: 0.4345, 验证准确率: 0.8764\n",
      "最终阶段 轮次 56/100, 训练损失: 0.4220, 验证损失: 0.4282, 验证准确率: 0.8381\n",
      "最终阶段 轮次 57/100, 训练损失: 0.4162, 验证损失: 0.4085, 验证准确率: 0.8898\n",
      "最终阶段 轮次 58/100, 训练损失: 0.4063, 验证损失: 0.4051, 验证准确率: 0.8929\n",
      "最终阶段 轮次 59/100, 训练损失: 0.3983, 验证损失: 0.3926, 验证准确率: 0.8808\n",
      "最终阶段 轮次 60/100, 训练损失: 0.3959, 验证损失: 0.3901, 验证准确率: 0.8814\n",
      "最终阶段 轮次 61/100, 训练损失: 0.3841, 验证损失: 0.3816, 验证准确率: 0.8860\n",
      "最终阶段 轮次 62/100, 训练损失: 0.3794, 验证损失: 0.3768, 验证准确率: 0.8755\n",
      "最终阶段 轮次 63/100, 训练损失: 0.3769, 验证损失: 0.3722, 验证准确率: 0.8858\n",
      "最终阶段 轮次 64/100, 训练损失: 0.3681, 验证损失: 0.3908, 验证准确率: 0.8905\n",
      "最终阶段 轮次 65/100, 训练损失: 0.3615, 验证损失: 0.3657, 验证准确率: 0.8723\n",
      "最终阶段 轮次 66/100, 训练损失: 0.3563, 验证损失: 0.3648, 验证准确率: 0.8809\n",
      "最终阶段 轮次 67/100, 训练损失: 0.3515, 验证损失: 0.3450, 验证准确率: 0.8880\n",
      "最终阶段 轮次 68/100, 训练损失: 0.3457, 验证损失: 0.3640, 验证准确率: 0.8813\n",
      "最终阶段 轮次 69/100, 训练损失: 0.3426, 验证损失: 0.3564, 验证准确率: 0.8853\n",
      "最终阶段 轮次 70/100, 训练损失: 0.3318, 验证损失: 0.3397, 验证准确率: 0.8905\n",
      "最终阶段 轮次 71/100, 训练损失: 0.3291, 验证损失: 0.3338, 验证准确率: 0.9006\n",
      "最终阶段 轮次 72/100, 训练损失: 0.3219, 验证损失: 0.3198, 验证准确率: 0.8886\n",
      "最终阶段 轮次 73/100, 训练损失: 0.3188, 验证损失: 0.3122, 验证准确率: 0.9011\n",
      "最终阶段 轮次 74/100, 训练损失: 0.3122, 验证损失: 0.3089, 验证准确率: 0.9023\n",
      "最终阶段 轮次 75/100, 训练损失: 0.3087, 验证损失: 0.3057, 验证准确率: 0.9021\n",
      "最终阶段 轮次 76/100, 训练损失: 0.3041, 验证损失: 0.3309, 验证准确率: 0.8996\n",
      "最终阶段 轮次 77/100, 训练损失: 0.3010, 验证损失: 0.2987, 验证准确率: 0.8950\n",
      "最终阶段 轮次 78/100, 训练损失: 0.2942, 验证损失: 0.2910, 验证准确率: 0.9038\n",
      "最终阶段 轮次 79/100, 训练损失: 0.2937, 验证损失: 0.2920, 验证准确率: 0.9111\n",
      "最终阶段 轮次 80/100, 训练损失: 0.2885, 验证损失: 0.2823, 验证准确率: 0.9130\n",
      "最终阶段 轮次 81/100, 训练损失: 0.2827, 验证损失: 0.2796, 验证准确率: 0.9033\n",
      "最终阶段 轮次 82/100, 训练损失: 0.2813, 验证损失: 0.2748, 验证准确率: 0.9130\n",
      "最终阶段 轮次 83/100, 训练损失: 0.2769, 验证损失: 0.2709, 验证准确率: 0.9086\n",
      "最终阶段 轮次 84/100, 训练损失: 0.2728, 验证损失: 0.2720, 验证准确率: 0.9040\n",
      "最终阶段 轮次 85/100, 训练损失: 0.2765, 验证损失: 0.2640, 验证准确率: 0.9106\n",
      "最终阶段 轮次 86/100, 训练损失: 0.2651, 验证损失: 0.2685, 验证准确率: 0.9200\n",
      "最终阶段 轮次 87/100, 训练损失: 0.2642, 验证损失: 0.3248, 验证准确率: 0.8926\n",
      "最终阶段 轮次 88/100, 训练损失: 0.2617, 验证损失: 0.2628, 验证准确率: 0.9151\n",
      "最终阶段 轮次 89/100, 训练损失: 0.2591, 验证损失: 0.2542, 验证准确率: 0.9128\n",
      "最终阶段 轮次 90/100, 训练损失: 0.2539, 验证损失: 0.2496, 验证准确率: 0.9204\n",
      "最终阶段 轮次 91/100, 训练损失: 0.2531, 验证损失: 0.2574, 验证准确率: 0.9149\n",
      "最终阶段 轮次 92/100, 训练损失: 0.2495, 验证损失: 0.2431, 验证准确率: 0.9290\n",
      "最终阶段 轮次 93/100, 训练损失: 0.2462, 验证损失: 0.2566, 验证准确率: 0.9141\n",
      "最终阶段 轮次 94/100, 训练损失: 0.2447, 验证损失: 0.2405, 验证准确率: 0.9163\n",
      "最终阶段 轮次 95/100, 训练损失: 0.2430, 验证损失: 0.2392, 验证准确率: 0.9170\n",
      "最终阶段 轮次 96/100, 训练损失: 0.2418, 验证损失: 0.2359, 验证准确率: 0.9171\n",
      "最终阶段 轮次 97/100, 训练损失: 0.2373, 验证损失: 0.2452, 验证准确率: 0.9193\n",
      "最终阶段 轮次 98/100, 训练损失: 0.2347, 验证损失: 0.2441, 验证准确率: 0.9123\n",
      "最终阶段 轮次 99/100, 训练损失: 0.2331, 验证损失: 0.2284, 验证准确率: 0.9331\n",
      "最终阶段 轮次 100/100, 训练损失: 0.2306, 验证损失: 0.2323, 验证准确率: 0.9264\n",
      "轮次 1/150, 训练损失: 0.5774, 验证损失: 0.4301, 验证准确率: 0.8280\n",
      "轮次 2/150, 训练损失: 0.4373, 验证损失: 0.4711, 验证准确率: 0.7970\n",
      "轮次 3/150, 训练损失: 0.3786, 验证损失: 0.3322, 验证准确率: 0.8580\n",
      "轮次 4/150, 训练损失: 0.3582, 验证损失: 0.3246, 验证准确率: 0.8660\n",
      "轮次 5/150, 训练损失: 0.3462, 验证损失: 0.3547, 验证准确率: 0.8350\n",
      "轮次 6/150, 训练损失: 0.3461, 验证损失: 0.3898, 验证准确率: 0.8300\n",
      "轮次 7/150, 训练损失: 0.3422, 验证损失: 0.3414, 验证准确率: 0.8420\n",
      "轮次 8/150, 训练损失: 0.3456, 验证损失: 0.3244, 验证准确率: 0.8650\n",
      "轮次 9/150, 训练损失: 0.3522, 验证损失: 0.3755, 验证准确率: 0.8530\n",
      "轮次 10/150, 训练损失: 0.3416, 验证损失: 0.3601, 验证准确率: 0.8760\n",
      "轮次 11/150, 训练损失: 0.3371, 验证损失: 0.3229, 验证准确率: 0.8650\n",
      "轮次 12/150, 训练损失: 0.3380, 验证损失: 0.3218, 验证准确率: 0.8630\n",
      "轮次 13/150, 训练损失: 0.3342, 验证损失: 0.3385, 验证准确率: 0.8550\n",
      "轮次 14/150, 训练损失: 0.3453, 验证损失: 0.3331, 验证准确率: 0.8510\n",
      "轮次 15/150, 训练损失: 0.3367, 验证损失: 0.3238, 验证准确率: 0.8590\n",
      "轮次 16/150, 训练损失: 0.3339, 验证损失: 0.3229, 验证准确率: 0.8570\n",
      "轮次 17/150, 训练损失: 0.3366, 验证损失: 0.3329, 验证准确率: 0.8690\n",
      "轮次 18/150, 训练损失: 0.3441, 验证损失: 0.4012, 验证准确率: 0.8250\n",
      "轮次 19/150, 训练损失: 0.3405, 验证损失: 0.3224, 验证准确率: 0.8610\n",
      "轮次 20/150, 训练损失: 0.3324, 验证损失: 0.3234, 验证准确率: 0.8540\n",
      "轮次 21/150, 训练损失: 0.3330, 验证损失: 0.3549, 验证准确率: 0.8590\n",
      "轮次 22/150, 训练损失: 0.3490, 验证损失: 0.3405, 验证准确率: 0.8650\n",
      "轮次 23/150, 训练损失: 0.3294, 验证损失: 0.3156, 验证准确率: 0.8660\n",
      "轮次 24/150, 训练损失: 0.3385, 验证损失: 0.3506, 验证准确率: 0.8480\n",
      "轮次 25/150, 训练损失: 0.3343, 验证损失: 0.4329, 验证准确率: 0.8040\n",
      "轮次 26/150, 训练损失: 0.3456, 验证损失: 0.3645, 验证准确率: 0.8500\n",
      "轮次 27/150, 训练损失: 0.3413, 验证损失: 0.3442, 验证准确率: 0.8590\n",
      "轮次 28/150, 训练损失: 0.3272, 验证损失: 0.3325, 验证准确率: 0.8580\n",
      "轮次 29/150, 训练损失: 0.3329, 验证损失: 0.3715, 验证准确率: 0.8570\n",
      "轮次 30/150, 训练损失: 0.3355, 验证损失: 0.3322, 验证准确率: 0.8780\n",
      "轮次 31/150, 训练损失: 0.3264, 验证损失: 0.3158, 验证准确率: 0.8650\n",
      "轮次 32/150, 训练损失: 0.3270, 验证损失: 0.4294, 验证准确率: 0.8100\n",
      "轮次 33/150, 训练损失: 0.3319, 验证损失: 0.3204, 验证准确率: 0.8650\n",
      "轮次 34/150, 训练损失: 0.3276, 验证损失: 0.3158, 验证准确率: 0.8680\n",
      "轮次 35/150, 训练损失: 0.3274, 验证损失: 0.3294, 验证准确率: 0.8610\n",
      "轮次 36/150, 训练损失: 0.3292, 验证损失: 0.3167, 验证准确率: 0.8720\n",
      "轮次 37/150, 训练损失: 0.3237, 验证损失: 0.3294, 验证准确率: 0.8550\n",
      "轮次 38/150, 训练损失: 0.3262, 验证损失: 0.3367, 验证准确率: 0.8630\n",
      "轮次 39/150, 训练损失: 0.3348, 验证损失: 0.3165, 验证准确率: 0.8760\n",
      "轮次 40/150, 训练损失: 0.3339, 验证损失: 0.3191, 验证准确率: 0.8770\n",
      "轮次 41/150, 训练损失: 0.3251, 验证损失: 0.3137, 验证准确率: 0.8670\n",
      "轮次 42/150, 训练损失: 0.3208, 验证损失: 0.3634, 验证准确率: 0.8550\n",
      "轮次 43/150, 训练损失: 0.3257, 验证损失: 0.3340, 验证准确率: 0.8730\n",
      "轮次 44/150, 训练损失: 0.3482, 验证损失: 0.3173, 验证准确率: 0.8750\n",
      "轮次 45/150, 训练损失: 0.3267, 验证损失: 0.3171, 验证准确率: 0.8830\n",
      "轮次 46/150, 训练损失: 0.3196, 验证损失: 0.3167, 验证准确率: 0.8790\n",
      "轮次 47/150, 训练损失: 0.3276, 验证损失: 0.3698, 验证准确率: 0.8630\n",
      "轮次 48/150, 训练损失: 0.3309, 验证损失: 0.3085, 验证准确率: 0.8780\n",
      "轮次 49/150, 训练损失: 0.3260, 验证损失: 0.3101, 验证准确率: 0.8760\n",
      "轮次 50/150, 训练损失: 0.3246, 验证损失: 0.3794, 验证准确率: 0.8610\n",
      "轮次 51/150, 训练损失: 0.3209, 验证损失: 0.3261, 验证准确率: 0.8430\n",
      "轮次 52/150, 训练损失: 0.3325, 验证损失: 0.3777, 验证准确率: 0.8350\n",
      "轮次 53/150, 训练损失: 0.3374, 验证损失: 0.3398, 验证准确率: 0.8560\n",
      "轮次 54/150, 训练损失: 0.3245, 验证损失: 0.3084, 验证准确率: 0.8770\n",
      "轮次 55/150, 训练损失: 0.3154, 验证损失: 0.3066, 验证准确率: 0.8800\n",
      "轮次 56/150, 训练损失: 0.3203, 验证损失: 0.3291, 验证准确率: 0.8480\n",
      "轮次 57/150, 训练损失: 0.3195, 验证损失: 0.3043, 验证准确率: 0.8820\n",
      "轮次 58/150, 训练损失: 0.3145, 验证损失: 0.3016, 验证准确率: 0.8680\n",
      "轮次 59/150, 训练损失: 0.3172, 验证损失: 0.3256, 验证准确率: 0.8620\n",
      "轮次 60/150, 训练损失: 0.3277, 验证损失: 0.3491, 验证准确率: 0.8510\n",
      "轮次 61/150, 训练损失: 0.3212, 验证损失: 0.3149, 验证准确率: 0.8640\n",
      "轮次 62/150, 训练损失: 0.3154, 验证损失: 0.3299, 验证准确率: 0.8790\n",
      "轮次 63/150, 训练损失: 0.3155, 验证损失: 0.3014, 验证准确率: 0.8840\n",
      "轮次 64/150, 训练损失: 0.3171, 验证损失: 0.3369, 验证准确率: 0.8820\n",
      "轮次 65/150, 训练损失: 0.3273, 验证损失: 0.3053, 验证准确率: 0.8670\n",
      "轮次 66/150, 训练损失: 0.3247, 验证损失: 0.3041, 验证准确率: 0.8780\n",
      "轮次 67/150, 训练损失: 0.3162, 验证损失: 0.3108, 验证准确率: 0.8860\n",
      "轮次 68/150, 训练损失: 0.3232, 验证损失: 0.3680, 验证准确率: 0.8430\n",
      "轮次 69/150, 训练损失: 0.3182, 验证损失: 0.3041, 验证准确率: 0.8820\n",
      "轮次 70/150, 训练损失: 0.3126, 验证损失: 0.3007, 验证准确率: 0.8850\n",
      "轮次 71/150, 训练损失: 0.3311, 验证损失: 0.3904, 验证准确率: 0.8320\n",
      "轮次 72/150, 训练损失: 0.3270, 验证损失: 0.3067, 验证准确率: 0.8780\n",
      "轮次 73/150, 训练损失: 0.3198, 验证损失: 0.2989, 验证准确率: 0.8740\n",
      "轮次 74/150, 训练损失: 0.3215, 验证损失: 0.2963, 验证准确率: 0.8840\n",
      "轮次 75/150, 训练损失: 0.3090, 验证损失: 0.3308, 验证准确率: 0.8570\n",
      "轮次 76/150, 训练损失: 0.3115, 验证损失: 0.2983, 验证准确率: 0.8680\n",
      "轮次 77/150, 训练损失: 0.3161, 验证损失: 0.3018, 验证准确率: 0.8840\n",
      "轮次 78/150, 训练损失: 0.3120, 验证损失: 0.3015, 验证准确率: 0.8770\n",
      "轮次 79/150, 训练损失: 0.3088, 验证损失: 0.2931, 验证准确率: 0.8810\n",
      "轮次 80/150, 训练损失: 0.3226, 验证损失: 0.3027, 验证准确率: 0.8610\n",
      "轮次 81/150, 训练损失: 0.3149, 验证损失: 0.3234, 验证准确率: 0.8800\n",
      "轮次 82/150, 训练损失: 0.3106, 验证损失: 0.3140, 验证准确率: 0.8840\n",
      "轮次 83/150, 训练损失: 0.3085, 验证损失: 0.2955, 验证准确率: 0.8890\n",
      "轮次 84/150, 训练损失: 0.3068, 验证损失: 0.3106, 验证准确率: 0.8750\n",
      "轮次 85/150, 训练损失: 0.3058, 验证损失: 0.3373, 验证准确率: 0.8330\n",
      "轮次 86/150, 训练损失: 0.3112, 验证损失: 0.3071, 验证准确率: 0.8930\n",
      "轮次 87/150, 训练损失: 0.3102, 验证损失: 0.2918, 验证准确率: 0.8870\n",
      "轮次 88/150, 训练损失: 0.3115, 验证损失: 0.2970, 验证准确率: 0.8620\n",
      "轮次 89/150, 训练损失: 0.3106, 验证损失: 0.3221, 验证准确率: 0.8620\n",
      "轮次 90/150, 训练损失: 0.3189, 验证损失: 0.2948, 验证准确率: 0.8730\n",
      "轮次 91/150, 训练损失: 0.3073, 验证损失: 0.3010, 验证准确率: 0.8820\n",
      "轮次 92/150, 训练损失: 0.3190, 验证损失: 0.3114, 验证准确率: 0.8670\n",
      "轮次 93/150, 训练损失: 0.3076, 验证损失: 0.2911, 验证准确率: 0.8750\n",
      "轮次 94/150, 训练损失: 0.3167, 验证损失: 0.3002, 验证准确率: 0.8820\n",
      "轮次 95/150, 训练损失: 0.3029, 验证损失: 0.3372, 验证准确率: 0.8680\n",
      "轮次 96/150, 训练损失: 0.3048, 验证损失: 0.2981, 验证准确率: 0.8730\n",
      "轮次 97/150, 训练损失: 0.3049, 验证损失: 0.3269, 验证准确率: 0.8520\n",
      "轮次 98/150, 训练损失: 0.3048, 验证损失: 0.3431, 验证准确率: 0.8610\n",
      "轮次 99/150, 训练损失: 0.3044, 验证损失: 0.4164, 验证准确率: 0.8230\n",
      "轮次 100/150, 训练损失: 0.3351, 验证损失: 0.2870, 验证准确率: 0.8770\n",
      "轮次 101/150, 训练损失: 0.3025, 验证损失: 0.3109, 验证准确率: 0.8730\n",
      "轮次 102/150, 训练损失: 0.3068, 验证损失: 0.2918, 验证准确率: 0.8740\n",
      "轮次 103/150, 训练损失: 0.3088, 验证损失: 0.3246, 验证准确率: 0.8600\n",
      "轮次 104/150, 训练损失: 0.3132, 验证损失: 0.3142, 验证准确率: 0.8750\n",
      "轮次 105/150, 训练损失: 0.2992, 验证损失: 0.3026, 验证准确率: 0.8740\n",
      "轮次 106/150, 训练损失: 0.3057, 验证损失: 0.3123, 验证准确率: 0.8650\n",
      "轮次 107/150, 训练损失: 0.3049, 验证损失: 0.4596, 验证准确率: 0.7860\n",
      "轮次 108/150, 训练损失: 0.3098, 验证损失: 0.3340, 验证准确率: 0.8670\n",
      "轮次 109/150, 训练损失: 0.3006, 验证损失: 0.2880, 验证准确率: 0.8780\n",
      "轮次 110/150, 训练损失: 0.2970, 验证损失: 0.2881, 验证准确率: 0.8780\n",
      "轮次 111/150, 训练损失: 0.2998, 验证损失: 0.3139, 验证准确率: 0.8760\n",
      "轮次 112/150, 训练损失: 0.3087, 验证损失: 0.2880, 验证准确率: 0.8800\n",
      "轮次 113/150, 训练损失: 0.3083, 验证损失: 0.2908, 验证准确率: 0.8890\n",
      "轮次 114/150, 训练损失: 0.2994, 验证损失: 0.3080, 验证准确率: 0.8800\n",
      "轮次 115/150, 训练损失: 0.2998, 验证损失: 0.2819, 验证准确率: 0.8810\n",
      "轮次 116/150, 训练损失: 0.3017, 验证损失: 0.2826, 验证准确率: 0.8870\n",
      "轮次 117/150, 训练损失: 0.3015, 验证损失: 0.2813, 验证准确率: 0.8880\n",
      "轮次 118/150, 训练损失: 0.2981, 验证损失: 0.3229, 验证准确率: 0.8610\n",
      "轮次 119/150, 训练损失: 0.3104, 验证损失: 0.2951, 验证准确率: 0.8740\n",
      "轮次 120/150, 训练损失: 0.2994, 验证损失: 0.3387, 验证准确率: 0.8620\n",
      "轮次 121/150, 训练损失: 0.2981, 验证损失: 0.2919, 验证准确率: 0.8770\n",
      "轮次 122/150, 训练损失: 0.3051, 验证损失: 0.2843, 验证准确率: 0.8790\n",
      "轮次 123/150, 训练损失: 0.3027, 验证损失: 0.2818, 验证准确率: 0.8940\n",
      "轮次 124/150, 训练损失: 0.2927, 验证损失: 0.2826, 验证准确率: 0.8910\n",
      "轮次 125/150, 训练损失: 0.2993, 验证损失: 0.3884, 验证准确率: 0.8100\n",
      "轮次 126/150, 训练损失: 0.3043, 验证损失: 0.2802, 验证准确率: 0.8810\n",
      "轮次 127/150, 训练损失: 0.3020, 验证损失: 0.2925, 验证准确率: 0.8830\n",
      "轮次 128/150, 训练损失: 0.3064, 验证损失: 0.2908, 验证准确率: 0.8730\n",
      "轮次 129/150, 训练损失: 0.2935, 验证损失: 0.3339, 验证准确率: 0.8720\n",
      "轮次 130/150, 训练损失: 0.3008, 验证损失: 0.2766, 验证准确率: 0.8760\n",
      "轮次 131/150, 训练损失: 0.2911, 验证损失: 0.2806, 验证准确率: 0.8860\n",
      "轮次 132/150, 训练损失: 0.2916, 验证损失: 0.2795, 验证准确率: 0.8850\n",
      "轮次 133/150, 训练损失: 0.3011, 验证损失: 0.3136, 验证准确率: 0.8670\n",
      "轮次 134/150, 训练损失: 0.2986, 验证损失: 0.3299, 验证准确率: 0.8610\n",
      "轮次 135/150, 训练损失: 0.3003, 验证损失: 0.2781, 验证准确率: 0.8900\n",
      "轮次 136/150, 训练损失: 0.2932, 验证损失: 0.2835, 验证准确率: 0.8820\n",
      "轮次 137/150, 训练损失: 0.3049, 验证损失: 0.2801, 验证准确率: 0.8850\n",
      "轮次 138/150, 训练损失: 0.2895, 验证损失: 0.2749, 验证准确率: 0.8760\n",
      "轮次 139/150, 训练损失: 0.3011, 验证损失: 0.2853, 验证准确率: 0.8860\n",
      "轮次 140/150, 训练损失: 0.2949, 验证损失: 0.2839, 验证准确率: 0.8710\n",
      "轮次 141/150, 训练损失: 0.2923, 验证损失: 0.2759, 验证准确率: 0.8870\n",
      "轮次 142/150, 训练损失: 0.3014, 验证损失: 0.2787, 验证准确率: 0.8720\n",
      "轮次 143/150, 训练损失: 0.2921, 验证损失: 0.2732, 验证准确率: 0.8850\n",
      "轮次 144/150, 训练损失: 0.3027, 验证损失: 0.2971, 验证准确率: 0.8860\n",
      "轮次 145/150, 训练损失: 0.3015, 验证损失: 0.2871, 验证准确率: 0.8830\n",
      "轮次 146/150, 训练损失: 0.3100, 验证损失: 0.2778, 验证准确率: 0.8790\n",
      "轮次 147/150, 训练损失: 0.2918, 验证损失: 0.2786, 验证准确率: 0.8830\n",
      "轮次 148/150, 训练损失: 0.2950, 验证损失: 0.2867, 验证准确率: 0.8910\n",
      "轮次 149/150, 训练损失: 0.2891, 验证损失: 0.3349, 验证准确率: 0.8510\n",
      "轮次 150/150, 训练损失: 0.3151, 验证损失: 0.2934, 验证准确率: 0.8750\n",
      "原始输出: [[0.06156062 0.93843937]]\n",
      "123.45 + 678.90 = 802.35 的正确概率: 0.9384, 实际上是: 正确\n",
      "原始输出: [[0.18002757 0.8199724 ]]\n",
      "456.78 + 321.09 = 777.87 的正确概率: 0.8200, 实际上是: 正确\n",
      "原始输出: [[0.99883693 0.00116302]]\n",
      "789.12 + 345.67 = 1200.00 的正确概率: 0.0012, 实际上是: 错误\n",
      "原始输出: [[0.09498384 0.9050161 ]]\n",
      "1234.56 + 7890.12 = 9124.68 的正确概率: 0.9050, 实际上是: 正确\n",
      "原始输出: [[0.94326186 0.05673808]]\n",
      "2345.67 + 8901.23 = 11000.00 的正确概率: 0.0567, 实际上是: 错误\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = generate_data(num_samples=80000, max_value=10000)\n",
    "X_val, y_val = generate_data(num_samples=1000, max_value=10000)\n",
    "X_test, y_test = generate_data(num_samples=2000, max_value=10000)\n",
    "\n",
    "# 将数据移到GPU\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_val = X_val.to(device)\n",
    "y_val = y_val.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "def init_xavier(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # 使用Xavier均匀分布初始化权重\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        # 将偏置初始化为小的正数，避免ReLU神经元\"死亡\"\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.01)\n",
    "\n",
    "# 创建模型并移到GPU\n",
    "model = AdditionNet().to(device)\n",
    "model.apply(init_xavier)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model = curriculum_training(model)\n",
    "\n",
    "# 训练模型\n",
    "epochs = 150\n",
    "batch_size = 1024\n",
    "losses = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 100  # 早停耐心值\n",
    "no_improve = 0\n",
    "accuracy_threshold = 0.996\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\tmodel.train()\n",
    "\ttotal_loss = 0\n",
    "\t# 获取随机批次\n",
    "\tindices = torch.randperm(len(X_train))\n",
    "\tfor i in range(0, len(X_train), batch_size):\n",
    "\t\tbatch_indices = indices[i:i+batch_size]\n",
    "\t\tinputs = X_train[batch_indices]\n",
    "\t\ttargets = y_train[batch_indices]\n",
    "\t\t\n",
    "\t\t# 前向传播\n",
    "\t\toutputs = model(inputs)\n",
    "\t\tloss = criterion(outputs, targets)\n",
    "\t\t\n",
    "\t\t# 反向传播和优化\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\n",
    "\t\ttotal_loss += loss.item()\n",
    "\t\t\n",
    "\ttrain_loss = total_loss / (len(X_train) / batch_size)\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tval_outputs = model(X_val)\n",
    "\t\tval_loss = criterion(val_outputs, y_val).item()\n",
    "\t\t\n",
    "\t\t_, val_predicted = torch.max(val_outputs, 1)\n",
    "\t\t_, val_true_labels = torch.max(y_val, 1)\n",
    "\t\tval_accuracy = (val_predicted == val_true_labels).float().mean().item()\n",
    "\n",
    "\tprint(f'轮次 {epoch+1}/{epochs}, 训练损失: {train_loss:.4f}, 验证损失: {val_loss:.4f}, 验证准确率: {val_accuracy:.4f}')\n",
    "\n",
    "\t# 早停检查\n",
    "\tif val_loss < best_val_loss:\n",
    "\t\tbest_val_loss = val_loss\n",
    "\t\ttorch.save(model.state_dict(), 'best_model.pt')\n",
    "\t\tno_improve = 0\n",
    "\telse:\n",
    "\t\tno_improve += 1\n",
    "\n",
    "\t# 准确率达到阈值时停止\n",
    "\tif val_accuracy >= accuracy_threshold:\n",
    "\t\tprint(f'验证准确率达到 {val_accuracy:.4f}，在第 {epoch+1} 轮停止训练')\n",
    "\t\tbreak\n",
    "\t\t\n",
    "\t# 早停检查\n",
    "\tif no_improve >= patience:\n",
    "\t\tprint(f'连续 {patience} 轮未改善，在第 {epoch+1} 轮停止训练')\n",
    "\t\tbreak\n",
    "\n",
    "# 修改check_addition函数以使用GPU\n",
    "def check_addition(a, b, c, max_value=10000):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        a_norm, b_norm, c_norm = normalize_data_log(a, b, c, max_value)\n",
    "        input_data = torch.tensor([[a_norm, b_norm, c_norm]], dtype=torch.float32).to(device)\n",
    "        probabilities = model(input_data)\n",
    "        # 打印原始输出，帮助调试\n",
    "        print(f\"原始输出: {probabilities.cpu().numpy()}\")\n",
    "        return probabilities[0, 1].item()  # 返回正确的概率(索引1)\n",
    "\n",
    "# 测试示例\n",
    "decimal_examples = [\n",
    "    (123.45, 678.90, 802.35),   # 正确: 123.45 + 678.90 = 802.35\n",
    "    (456.78, 321.09, 777.87),   # 正确: 456.78 + 321.09 = 777.87\n",
    "    (789.12, 345.67, 1200.00),  # 错误: 789.12 + 345.67 ≠ 1200.00\n",
    "    (1234.56, 7890.12, 9124.68),# 正确: 1234.56 + 7890.12 = 9124.68\n",
    "    (2345.67, 8901.23, 11000.00)# 错误: 2345.67 + 8901.23 ≠ 11000.00\n",
    "]\n",
    "\n",
    "for a, b, c in decimal_examples:\n",
    "    prob = check_addition(a, b, c)\n",
    "    correct = abs((a + b) - c) < 1e-5\n",
    "    print(f'{a:.2f} + {b:.2f} = {c:.2f} 的正确概率: {prob:.4f}, 实际上是: {\"正确\" if correct else \"错误\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
