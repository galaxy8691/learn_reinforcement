{"cells":[{"cell_type":"code","execution_count":16,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-08T06:20:23.469480Z","iopub.status.busy":"2024-10-08T06:20:23.468938Z","iopub.status.idle":"2024-10-08T06:20:58.399663Z","shell.execute_reply":"2024-10-08T06:20:58.397435Z","shell.execute_reply.started":"2024-10-08T06:20:23.469427Z"},"trusted":true},"outputs":[],"source":["#!pip install gymnasium\n","#!pip install swig\n","#!pip install gymnasium[box2d]\n","from IPython import display\n","%matplotlib inline\n","import gymnasium as gym\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","import time\n","import random\n","#torch.set_default_device('cuda')"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:53:22.405286Z","iopub.status.busy":"2024-10-08T05:53:22.404705Z","iopub.status.idle":"2024-10-08T05:53:22.411733Z","shell.execute_reply":"2024-10-08T05:53:22.410500Z","shell.execute_reply.started":"2024-10-08T05:53:22.405227Z"},"trusted":true},"outputs":[],"source":["from PIL import Image\n","import numpy as np\n","def display_image(imageArray):\n","    display.display(Image.fromarray(np.array(imageArray),'RGB'),clear=True)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T06:34:43.816121Z","iopub.status.busy":"2024-10-08T06:34:43.815682Z","iopub.status.idle":"2024-10-08T06:34:43.821833Z","shell.execute_reply":"2024-10-08T06:34:43.820600Z","shell.execute_reply.started":"2024-10-08T06:34:43.816076Z"},"trusted":true},"outputs":[],"source":["from collections import namedtuple\n","Transition  = namedtuple('Transition', ('state','action', 'state_next','reward'))"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net,self).__init__()\n","        self.fc1 = nn.Linear(4,32)\n","        self.fc2 = nn.Linear(32,32)\n","        self.fc3 = nn.Linear(32,2)\n","\n","    def forward(self,x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T08:51:01.510227Z","iopub.status.busy":"2024-10-08T08:51:01.509774Z","iopub.status.idle":"2024-10-08T08:51:01.534557Z","shell.execute_reply":"2024-10-08T08:51:01.533101Z","shell.execute_reply.started":"2024-10-08T08:51:01.510181Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","MAX_STEP = 500\n","NUM_EPISODE = 500\n","CAPACITY = 10000\n","BATCH_SIZE = 32\n","GAMMA = 0.99\n","memory = []\n","index = 0\n","target_count = 100\n","target_suceess_count = 0\n","\n","main_model = Net()\n","main_model.to(device)\n","target_model = Net()\n","target_model.to(device)\n","\n","optimizer = optim.Adam(main_model.parameters(), lr=0.00005)\n","\n","def push(state, action, state_next, reward):\n","    global index\n","    #print(index)\n","    if len(memory) < CAPACITY:\n","        memory.append(None)\n","    memory[index] = Transition(state,action,state_next, reward)\n","    index = (index + 1) % CAPACITY\n","\n","def sample(batch_size):\n","    return random.sample(memory,batch_size)\n","\n","def replay():\n","    if len(memory) < BATCH_SIZE:\n","        return\n","    transition = sample(BATCH_SIZE)\n","    batch = Transition(*zip(*transition))\n","    state_batch = torch.cat(batch.state).to(device)\n","    action_batch = torch.cat(batch.action).to(device)\n","    reward_batch = torch.cat(batch.reward).to(device)\n","    non_final_next_states = torch.cat([s for s in batch.state_next if s is not None]).to(device)\n","    main_model.eval()\n","    target_model.eval()\n","    state_action_value = main_model(state_batch).gather(1,action_batch)\n","    mask = torch.ByteTensor(tuple(map(lambda s: s is not None, batch.state_next))).to(device) != 0\n","    nsv = torch.zeros(BATCH_SIZE).to(device)\n","    nsv[mask] = target_model(non_final_next_states).max(1)[0].detach().to(device)\n","    expected_state_action_values = reward_batch + GAMMA * nsv\n","    main_model.train()\n","    loss = F.smooth_l1_loss(state_action_value, expected_state_action_values.unsqueeze(1))\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","def update_target_model():\n","    target_model.load_state_dict(main_model.state_dict())   \n","    \n","def reset(env):\n","      observation = env.reset()[0]\n","      return observation\n","\n","def reset_memory():\n","    global memory\n","    global index\n","    memory = []\n","    index = 0\n","\n","def get_action(s,epsilon):\n","    if np.random.rand() < epsilon:\n","        action = torch.LongTensor([[random.randrange(2)]]).to(device)\n","    else:\n","        main_model.eval()\n","        with torch.no_grad():\n","            action = main_model(s).max(1)[1].view(1,1)\n","    return action\n","\n","# def Q_learning(s, a, r, s_next, Q, eta, gamma, is_terminated):\n","#     s = digitize_state(s)\n","#     s_next = digitize_state(s_next)\n","#     if is_terminated:\n","#         Q[s, a] = Q[s, a] + eta * (r- Q[s, a])\n","#     else:\n","#         Q[s, a] = Q[s, a] + eta * (r + gamma * np.nanmax(Q[s_next, :]) - Q[s, a])\n","#     return Q\n","\n","def run_once(env, initial_observation, epsilon, show=False, train=True):\n","    global target_count, target_suceess_count\n","    observation = initial_observation\n","    s = torch.from_numpy(observation).type(torch.FloatTensor)\n","    s = torch.unsqueeze(s,0).to(device)\n","    a = get_action(s, epsilon)\n","    a_next = a\n","    count = 0;\n","  \n","    while True:\n","        is_terminated = False\n","        if show:\n","            time.sleep(0.01)\n","            img = env.render()\n","            display_image(img)\n","        a = a_next\n","        #s_a_history[-1][1] = a\n","        s_next, reward, terminated, truncated, info = env.step(a.item())\n","        s_next = torch.from_numpy(s_next).type(torch.FloatTensor)\n","        s_next = torch.unsqueeze(s_next,0).to(device)\n","        #s_a_history.append([s_next, np.nan])\n","        if count > target_count:\n","            r = torch.FloatTensor([1.0])\n","            a_next = None\n","            is_terminated = True\n","            s_next = None\n","            target_suceess_count += 1\n","            if target_count <= 900:\n","                if target_suceess_count > 10:\n","                    target_count += 100\n","                    target_suceess_count = 0\n","                    print(\"new target is \", target_count)\n","        elif count < target_count and terminated:\n","            r = torch.FloatTensor([-1.0])\n","            a_next = None\n","            is_terminated = True\n","            s_next = None\n","            target_suceess_count = 0\n","        else:\n","            r = torch.FloatTensor([0.0])\n","            a_next = get_action(s_next, epsilon)\n","        push(s, a, s_next, r)\n","        if train:\n","            \n","            replay()\n","            \n","        if is_terminated:\n","            if show:\n","                time.sleep(0.01)\n","                img = env.render()\n","                display_image(img)\n","            if train:\n","                update_target_model()\n","            break\n","        else:\n","            s = s_next\n","        count += 1\n","        "]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["# model = nn.Sequential()\n","# model.add_module('fc1',nn.Linear(4,32))\n","# model.add_module('relu1',nn.ReLU())\n","# model.add_module('fc2', nn.Linear(32,32))\n","# model.add_module('relu2', nn.ReLU())\n","# model.add_module('fc2', nn.Linear(32,2))\n","\n","a = []\n","memory=[]\n","memory.append(Transition(torch.Tensor([1,2,3,4]).unsqueeze(0),torch.Tensor([0]).unsqueeze(0),torch.Tensor([3,4,2,2]).unsqueeze(0),torch.Tensor([1]).unsqueeze(0)))\n","memory.append(Transition(torch.Tensor([5,5,7,6]).unsqueeze(0),torch.Tensor([1]).unsqueeze(0),torch.Tensor([7,0,2,0]).unsqueeze(0),torch.Tensor([0]).unsqueeze(0)))\n","memory.append(Transition(torch.Tensor([6,2,3,4]).unsqueeze(0),torch.Tensor([1]).unsqueeze(0),None,torch.Tensor([0]).unsqueeze(0)))\n","#memory.append(Transition([6,2,3,4],[1],[3,5,4,2],0))\n","batch = Transition(*zip(*memory))\n","\n","\n","\n","state_batch = torch.cat(batch.state)\n","action_batch = torch.cat(batch.action)\n","reward_batch = torch.cat(batch.reward)\n","non_final_next_states = torch.cat([s for s in batch.state_next if s is not None])\n","state_batch\n","model.eval()\n","model(state_batch).gather(1,action_batch.long())\n","mask = torch.ByteTensor(tuple(map(lambda s: s is not None, batch.state_next))) != 0\n","nsv = torch.zeros(3)\n","nsv[mask] = model(non_final_next_states).max(1)[0].detach()\n","\n","#model(state_batch[0].unsqueeze(1)).max(1)[1].view(1,1)\n","get_action(state_batch[0].unsqueeze(0),0).item()\n","#batch\n","#torch.cat(batch.reward)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:57:21.948645Z","iopub.status.busy":"2024-10-08T05:57:21.948192Z","iopub.status.idle":"2024-10-08T05:58:08.854997Z","shell.execute_reply":"2024-10-08T05:58:08.853789Z","shell.execute_reply.started":"2024-10-08T05:57:21.948601Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["episode: 100\n","episode: 200\n","new target is  200\n"]},{"name":"stderr","output_type":"stream","text":["d:\\miniconda3\\envs\\ml\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:180: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned terminated = True. You should always call 'reset()' once you receive 'terminated = True' -- any further steps are undefined behavior.\u001b[0m\n","  logger.warn(\n"]},{"name":"stdout","output_type":"stream","text":["episode: 300\n","new target is  300\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[25], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(episode))\n\u001b[0;32m     12\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m epsilon \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1.1\u001b[39m\n\u001b[1;32m---> 13\u001b[0m run_once(env, observation, epsilon, show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m episode \u001b[38;5;241m=\u001b[39m episode \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m episode \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m target_count \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n","Cell \u001b[1;32mIn[24], line 127\u001b[0m, in \u001b[0;36mrun_once\u001b[1;34m(env, initial_observation, epsilon, show, train)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train:\n\u001b[0;32m    126\u001b[0m     update_target_model()\n\u001b[1;32m--> 127\u001b[0m     replay()\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_terminated:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m show:\n","Cell \u001b[1;32mIn[24], line 50\u001b[0m, in \u001b[0;36mreplay\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     49\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 50\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[1;32md:\\miniconda3\\envs\\ml\\Lib\\site-packages\\torch\\optim\\optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m             )\n\u001b[1;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[1;32md:\\miniconda3\\envs\\ml\\Lib\\site-packages\\torch\\optim\\optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n","File \u001b[1;32md:\\miniconda3\\envs\\ml\\Lib\\site-packages\\torch\\optim\\adam.py:226\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    217\u001b[0m         group,\n\u001b[0;32m    218\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    223\u001b[0m         state_steps,\n\u001b[0;32m    224\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     adam(\n\u001b[0;32m    227\u001b[0m         params_with_grad,\n\u001b[0;32m    228\u001b[0m         grads,\n\u001b[0;32m    229\u001b[0m         exp_avgs,\n\u001b[0;32m    230\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    231\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    232\u001b[0m         state_steps,\n\u001b[0;32m    233\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    234\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    235\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    236\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    237\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    238\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    239\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    240\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    241\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    242\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    243\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    244\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    245\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    246\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    247\u001b[0m     )\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n","File \u001b[1;32md:\\miniconda3\\envs\\ml\\Lib\\site-packages\\torch\\optim\\optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32md:\\miniconda3\\envs\\ml\\Lib\\site-packages\\torch\\optim\\adam.py:766\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    764\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 766\u001b[0m func(\n\u001b[0;32m    767\u001b[0m     params,\n\u001b[0;32m    768\u001b[0m     grads,\n\u001b[0;32m    769\u001b[0m     exp_avgs,\n\u001b[0;32m    770\u001b[0m     exp_avg_sqs,\n\u001b[0;32m    771\u001b[0m     max_exp_avg_sqs,\n\u001b[0;32m    772\u001b[0m     state_steps,\n\u001b[0;32m    773\u001b[0m     amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m    774\u001b[0m     has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    775\u001b[0m     beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    776\u001b[0m     beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    777\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m    778\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m    779\u001b[0m     eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    780\u001b[0m     maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[0;32m    781\u001b[0m     capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[0;32m    782\u001b[0m     differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[0;32m    783\u001b[0m     grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[0;32m    784\u001b[0m     found_inf\u001b[38;5;241m=\u001b[39mfound_inf,\n\u001b[0;32m    785\u001b[0m )\n","File \u001b[1;32md:\\miniconda3\\envs\\ml\\Lib\\site-packages\\torch\\optim\\adam.py:415\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    413\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom)\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 415\u001b[0m     step \u001b[38;5;241m=\u001b[39m _get_value(step_t)\n\u001b[0;32m    417\u001b[0m     bias_correction1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mstep\n\u001b[0;32m    418\u001b[0m     bias_correction2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mstep\n","File \u001b[1;32md:\\miniconda3\\envs\\ml\\Lib\\site-packages\\torch\\optim\\optimizer.py:104\u001b[0m, in \u001b[0;36m_get_value\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m x\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["env = gym.make('CartPole-v1', render_mode='rgb_array')\n","epsilon = 0.5\n","is_continue = True\n","episode = 1\n","reset_memory()\n","target_count = 100\n","target_suceess_count = 0\n","while is_continue:\n","    observation = reset(env)\n","    if episode % 100 == 0:\n","        print('episode: ' + str(episode))\n","    epsilon = epsilon / 1.1\n","    run_once(env, observation, epsilon, show=False)\n","    episode = episode + 1\n","    if episode > 1000 or target_count >= 1000:\n","        break\n","env.close()"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T06:21:28.780907Z","iopub.status.busy":"2024-10-08T06:21:28.780440Z","iopub.status.idle":"2024-10-08T06:21:28.791620Z","shell.execute_reply":"2024-10-08T06:21:28.790200Z","shell.execute_reply.started":"2024-10-08T06:21:28.780860Z"},"trusted":true},"outputs":[{"data":{"image/jpeg":"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","image/png":"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","text/plain":["<PIL.Image.Image image mode=RGB size=600x400>"]},"metadata":{},"output_type":"display_data"}],"source":["env = gym.make('CartPole-v1', render_mode='rgb_array')\n","env.reset()\n","reset_memory()\n","observation = reset(env)\n","run_once(env, observation, 0, show=True, train=False)\n","# ss = torch.from_numpy(observation).type(torch.FloatTensor)\n","# ss = torch.unsqueeze(ss,0)\n","# ss"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[{"data":{"text/plain":["device(type='cuda', index=0)"]},"execution_count":99,"metadata":{},"output_type":"execute_result"}],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"ml","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":4}
